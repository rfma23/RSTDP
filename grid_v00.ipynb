{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic R-STDP Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an input for this basic R-STDP example we will give a `11x3` grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_dtype = np.dtype([('x', np.uint8), ('y', np.uint8), ('ts', np.float32)])\n",
    "c1_spike_dtype = np.dtype([('grid', np.uint8), ('y', np.uint8), ('x', np.uint8), ('ts', np.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grid:\n",
    "    \"\"\"\n",
    "        Each grid represents a pixel array with spikes occurring at\n",
    "        a certain location at the given timestamp.\n",
    "    \"\"\"\n",
    "    def __init__(self, xsize, ysize, grid):\n",
    "        self.xsize = xsize\n",
    "        self.ysize = ysize\n",
    "        self.grid = grid\n",
    "        \n",
    "    @classmethod\n",
    "    def get_grid(cls, i):\n",
    "        \"\"\"\n",
    "            Allows easy initialization of a grid\n",
    "        \"\"\"\n",
    "        if i == 0 :\n",
    "            grid = np.array([[0,0,0,0,0,0,0,0,0,0,0],\n",
    "                             [0,0,0,0,0,0,0,0,0,0,0],\n",
    "                             [0,0,0,0,0,0,0,0,0,0,0]],\n",
    "                           dtype=np.float32)\n",
    "        elif i == 1 :\n",
    "            grid = np.array([[1,0,0,0,5,6,7,0,0,0,9],\n",
    "                             [2,3,0,0,0,8,0,0,0,10,11],\n",
    "                             [4,0,0,0,0,0,0,0,0,0,12]],\n",
    "                           dtype=np.float32)\n",
    "            \n",
    "        elif i == 2 :\n",
    "            grid = np.array([[1,0,0,0,9,10,11,0,0,0,5],\n",
    "                             [2,3,0,0,0,12,0,0,0,6,7],\n",
    "                             [4,0,0,0,0,0,0,0,0,0,8]],\n",
    "                           dtype=np.float32)\n",
    "        else:\n",
    "            raise ValueError('Not a supported grid type')\n",
    "            \n",
    "        return cls(11, 3, grid)\n",
    "    \n",
    "    def show(self):\n",
    "        \"\"\"\n",
    "            Prints a visual representation of the grid including \n",
    "            spike's timestamps\n",
    "        \"\"\"\n",
    "        grayscale = (self.grid > 0).astype(int)\n",
    "        for (j, i), value in np.ndenumerate(self.grid):\n",
    "            if value > 0 : plt.text(i, j, int(value))\n",
    "        plt.imshow(grayscale, vmin=-1, vmax =1, cmap='gray')\n",
    "        plt.xticks(range(self.grid.shape[1]), rotation=0)\n",
    "        plt.show()\n",
    "    \n",
    "    @property\n",
    "    def spikes(self):\n",
    "        \"\"\"\n",
    "            Retrieves the grid spikes in a recarray format with\n",
    "            spikes sorted by timestamp\n",
    "        \"\"\"\n",
    "        grid_spikes = []\n",
    "        for (j, i), value in np.ndenumerate(self.grid):\n",
    "             if value > 0 : grid_spikes.append((i, j, value))\n",
    "        np_spikes = np.array(grid_spikes, dtype=spike_dtype)\n",
    "        np_spikes.sort(order='ts')\n",
    "        return np_spikes\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.grid.shape\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.spikes}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = Grid.get_grid(1)\n",
    "a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([( 0, 0,  1.), ( 0, 1,  2.), ( 1, 1,  3.), ( 0, 2,  4.),\n",
       "       ( 4, 0,  5.), ( 5, 0,  6.), ( 6, 0,  7.), ( 5, 1,  8.),\n",
       "       (10, 0,  9.), ( 9, 1, 10.), (10, 1, 11.), (10, 2, 12.)],\n",
       "      dtype=[('x', 'u1'), ('y', 'u1'), ('ts', '<f4')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = Grid.get_grid(2)\n",
    "b.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronal Grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neuronal grid has $n$ integrate-and-fire (IF) neurons with threshold $\\mathcal{T}$. Each neuron receives its inputs from a $\\omega \\times \\omega$ window -- also called the neuron's receptive field (RF) -- through weighted plastic synapses. In order to provide the ability of detecting a particular feature over the entire spatial positions, all the neurons belonging to the same grid share the same weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the arrival of a spike, we compute its relative position to a neuron $(x_r, y_r)$ and we increase the neuron's synaptic potential with the weight of the relative position if the spike is in its receptive field. In other words, the synaptic potential of neuron $i$ at time $t$ is: \n",
    "\n",
    "$$ v_i(t) = v_i(t-1) + \\sum_{(x_r, y_r) \\in {RF}}{w_{(x_r, y_r)} \\cdot \\delta(t-t_{spike}(j)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each neuronal grid detects a feature, the idea is to have multiple grids and associate each grid to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "import itertools \n",
    "import logging\n",
    "#logging.basicConfig(filename='grid_mac.log',\n",
    "                    #format='%(asctime)s | %(levelname)s | %(message)s',\n",
    "                    #level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronalGrids:\n",
    "    def __init__(self, input_grid_shape, neuron_rf=3, n_grids=4):\n",
    "        \n",
    "        self.input_grid_shape = input_grid_shape\n",
    "        self.grid_shape = ((input_grid_shape[0] - neuron_rf + 1),\n",
    "                           (input_grid_shape[1] - neuron_rf + 1))\n",
    "        \n",
    "        self.n_grids = n_grids\n",
    "        self.neuron_rf = neuron_rf\n",
    "        \n",
    "        self.synaptic_weights = self.initialise_weights(n_grids, neuron_rf)\n",
    "        self.neuron_potential = np.zeros((n_grids, *self.grid_shape), dtype=np.float32)\n",
    "        \n",
    "        self.sensitive_neurons_to_pos = self.get_sensitive_neurons()\n",
    "        self.neuron_threshold = 3.2\n",
    "        \n",
    "        self.reset_metrics()\n",
    "        self.Ar_plus = 0.075\n",
    "        self.Ar_neg = -0.05\n",
    "        self.Ap_plus = 0.04\n",
    "        self.Ap_neg = -0.1\n",
    "        \n",
    "        self.dropouts = []\n",
    "        \n",
    "        # to keep weights between [small_qty, 1-small_qty]\n",
    "        self.small_qty = 0.005\n",
    "    \n",
    "    def initialise_weights(self, n_grids, window_size, mu=0.8, sigma=0.05):\n",
    "        \"\"\"\n",
    "            Initialises the grid weights with values sampled from a normal\n",
    "            distribution mathcal{N}(mu, sigma2)\n",
    "        \"\"\"\n",
    "        # extract as many random samples as needed\n",
    "        grid = np.random.normal(mu, sigma, (n_grids, self.neuron_rf, self.neuron_rf))\n",
    "\n",
    "        # return them as a matrix\n",
    "        result = np.reshape(grid, (n_grids, self.neuron_rf, self.neuron_rf))\n",
    "        #result = np.full((n_grids, self.neuron_rf, self.neuron_rf), 0.8)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        self.n_silence = 0\n",
    "        self.n_hit = 0\n",
    "        self.n_miss = 0\n",
    "        self.n_samples = 0\n",
    "                \n",
    "    def get_temporal_winner(self, spikes, dropout=0.2, neuron_dropout=0.1):\n",
    "        \n",
    "        hasFired = False\n",
    "        is_active = np.random.random((self.n_grids))\n",
    "        is_active_neuron = np.random.random((self.grid_shape))\n",
    "        \n",
    "        for spike in spikes:\n",
    "            for grid in range(self.n_grids):\n",
    "                \n",
    "                if is_active[grid] > dropout:\n",
    "                    if not hasFired:\n",
    "\n",
    "                        affected_neurons = self.sensitive_neurons(spike)\n",
    "\n",
    "                        for neuron in affected_neurons:\n",
    "                            \n",
    "                            if is_active_neuron[neuron] > neuron_dropout:\n",
    "                                \n",
    "                                neuron_row, neuron_col = neuron\n",
    "                            \n",
    "                                relative_y, relative_x = self.relative_position(spike, neuron, self.neuron_rf)\n",
    "\n",
    "                                logging.info(f'Processing spike {spike}, Neuron {(neuron_row, neuron_col)}, Grid {grid}' + \\\n",
    "                                         f'Relative Pos {(relative_y, relative_x)}')\n",
    "                            \n",
    "                                self.neuron_potential[grid, neuron_row, neuron_col] += self.synaptic_weights[grid, relative_y, relative_x]\n",
    "\n",
    "                                if self.neuron_potential[grid, neuron_row, neuron_col] > self.neuron_threshold:\n",
    "                                    out_spike = np.array([(grid, neuron_row, neuron_col, spike['ts'])], dtype=c1_spike_dtype)\n",
    "                                    hasFired = True\n",
    "                                    break\n",
    "                                    \n",
    "                            # else ignore neuron\n",
    "\n",
    "                    else: # has fired\n",
    "                        return out_spike[0]\n",
    "                    \n",
    "                # else skip grid\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def predict(self, spikes):\n",
    "        \n",
    "        self.neuron_potential = np.zeros((self.n_grids, *self.grid_shape), dtype=np.float32)\n",
    "        winner_spike = self.get_temporal_winner(spikes, dropout=0, neuron_dropout=0)\n",
    "        \n",
    "        pred_class = None\n",
    "        \n",
    "        # if there is a winner: \n",
    "        if winner_spike is not None:\n",
    "            # get the class prediction of the winner\n",
    "            pred_class = winner_spike['grid'] % 2\n",
    "        \n",
    "        return pred_class\n",
    "        \n",
    "    def process(self, spikes, label, train=True):\n",
    "        \n",
    "        self.neuron_potential = np.zeros((self.n_grids, *self.grid_shape), dtype=np.float32)\n",
    "        \n",
    "        dropout=0.4*(1-self.n_hit/(self.n_samples+1))\n",
    "        neuron_dropout=0.2*(1-self.n_hit/(self.n_samples+1))\n",
    "        \n",
    "        self.dropouts.append((dropout, neuron_dropout))\n",
    "        \n",
    "        winner_spike = self.get_temporal_winner(spikes, dropout, neuron_dropout)\n",
    "        logging.info(winner_spike)\n",
    "        \n",
    "        # there can be no winners (no spikes), by default\n",
    "        reward = False\n",
    "        pred_class = None\n",
    "        \n",
    "        # if there is a winner: \n",
    "        if winner_spike is not None:\n",
    "            \n",
    "            # get the class prediction of the winner\n",
    "            pred_class = winner_spike['grid'] % 2\n",
    "            \n",
    "            # get the corresponding reward:\n",
    "            is_correct = (pred_class == label)\n",
    "            reward = is_correct\n",
    "            \n",
    "            logging.info(f'Reward {reward}, label {label}')\n",
    "            # compute metrics for performance and adjustment factor\n",
    "            self.n_hit += int(is_correct)\n",
    "            self.n_miss += int(is_correct)\n",
    "            \n",
    "            # if in training mode\n",
    "            if train:\n",
    "                # now we should trigger the learning process (only the winner grid updates its weights)\n",
    "                self.synaptic_plasticity(winner_spike, reward, spikes)\n",
    "        \n",
    "        # else there was no winner (silence)\n",
    "        else:\n",
    "            # increase all weights equally to the grids associated to the class\n",
    "            self.synaptic_weights[label] += 0.00005\n",
    "            # consider that for metrics\n",
    "            self.n_silence +=1\n",
    "            \n",
    "            # If none of the C2 neurons fire, no reward/punishment signal is generated, \n",
    "            # and thus, no weight change is applied.\n",
    "            \n",
    "                \n",
    "        # whatever the result, we processed one image\n",
    "        self.n_samples += 1\n",
    "        \n",
    "        return pred_class\n",
    "    \n",
    "    def synaptic_plasticity(self, winner_spike, reward, c1_spikes): \n",
    "        \n",
    "        \n",
    "        # self.synaptic_weights[winner_spike['grid']] contains the weights between C1 and S2, \n",
    "        # for a grid with one weight linking each orientation and (x,y) pixel\n",
    "        \n",
    "        grid_ix = winner_spike['grid']\n",
    "        \n",
    "        #if grid_ix==0: print(f\"Winner spike {winner_spike}, correct {reward}\")\n",
    "        # get whether there was a C1 spike relevant to neuron (in its receptive field)\n",
    "        # which spiked before the S2 spike\n",
    "        spiked_before_post = self.get_whether_pre_spiked_before_post(winner_spike, c1_spikes)\n",
    "        \n",
    "        # compute RSTDP update\n",
    "        computed_delta_weights = compute_RSTDP(self.synaptic_weights[grid_ix], spiked_before_post, reward, self.Ar_plus, self.Ar_neg, self.Ap_plus, self.Ap_neg)\n",
    "        \n",
    "        logging.info(f'Weights {self.synaptic_weights[grid_ix]}, Updates {computed_delta_weights}')\n",
    "        \n",
    "        # perform additive update rule with adaptive learning rate\n",
    "        if reward:\n",
    "            adjustment_factor = (self.n_miss+1)/(self.n_samples+1)\n",
    "        else:\n",
    "            adjustment_factor = (self.n_hit+1)/(self.n_samples+1)\n",
    "        \n",
    "        # apply the updates\n",
    "        apply_update(self.synaptic_weights[grid_ix], computed_delta_weights, adjustment_factor, self.small_qty)\n",
    "        \n",
    "    def relative_position(self, spike, neuron, neuron_rf):\n",
    "        row, col = neuron\n",
    "\n",
    "        relative_row = spike['y'] - row\n",
    "        relative_col = spike['x'] - col\n",
    "\n",
    "        return relative_row, relative_col\n",
    "    \n",
    "    \n",
    "    def get_sensitive_neurons(self):\n",
    "        \n",
    "        sensitive_neurons_to_pos = {}\n",
    "        for y, x in itertools.product(range(self.input_grid_shape[0]), range(self.input_grid_shape[1])) :\n",
    "            sensitive_neurons_to_pos[(y,x)] = []\n",
    "        \n",
    "        #print(sensitive_neurons_to_pos)\n",
    "        for row, col in itertools.product(range(self.grid_shape[0]), range(self.grid_shape[1])):\n",
    "            \n",
    "            neuron_center_row = row + self.neuron_rf//2\n",
    "            neuron_center_col = col + self.neuron_rf//2\n",
    "            \n",
    "            # relevant area for the neuron\n",
    "            row_lb = neuron_center_row-self.neuron_rf//2\n",
    "            row_ub = neuron_center_row+self.neuron_rf//2\n",
    "            col_lb = neuron_center_col-self.neuron_rf//2\n",
    "            col_ub = neuron_center_col+self.neuron_rf//2\n",
    "            \n",
    "            for y, x in itertools.product(range(row_lb, row_ub+1), range(col_lb, col_ub+1)):\n",
    "                sensitive_neurons_to_pos[(y,x)].append((row, col))\n",
    "                \n",
    "        return sensitive_neurons_to_pos\n",
    "                \n",
    "    def sensitive_neurons(self, spike):\n",
    "        return self.sensitive_neurons_to_pos[(spike['y'], spike['x'])]\n",
    "    \n",
    "    def get_whether_pre_spiked_before_post(self, s2_spike, c1_spikes):\n",
    "        \n",
    "        # we first need to understand which are the relevant rows and columns for an S2 neuron\n",
    "        # if a receptive field is 5x5 we have a relevant region in [0:4, 0:4] with center in 2,2\n",
    "        # this neuron centered in 2,2 is the S2 neuron (0,0), therefore:\n",
    "        \n",
    "        pre_spiked_before_post = np.full((self.neuron_rf, self.neuron_rf), False)\n",
    "        \n",
    "        neuron = (s2_spike['y'], s2_spike['x'])\n",
    "        \n",
    "        for spike in c1_spikes:\n",
    "            \n",
    "            #print(f\"Winner spike {s2_spike}, current spike {spike}\")\n",
    "            \n",
    "            if neuron in self.sensitive_neurons(spike):\n",
    "                relative_y, relative_x = self.relative_position(spike, neuron, self.neuron_rf)\n",
    "            \n",
    "                # and it spiked before\n",
    "                if(spike['ts'] <= s2_spike['ts']):\n",
    "                    \n",
    "                    #print(f\"Yeah it spiked before and relevant\")\n",
    "                    # we signal true:\n",
    "                    pre_spiked_before_post[relative_y, relative_x] = True\n",
    "                    \n",
    "               # else if silent or spiked later we keep it false\n",
    "            \n",
    "            # if not in receptive field we also keep it false\n",
    "            \n",
    "        return pre_spiked_before_post\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-STDP\n",
    "\n",
    "The weight updates are modulated by a reward/punishment signal which is received according to the correctness/incorrectness of the network's decision. The network's decision is given by the class associated to the grid which contains the first neuron to fire.\n",
    "\n",
    "If reward:\n",
    "$$\\Delta w_{ij} = \n",
    "\\begin{cases}\n",
    "a_r^+ \\times w_{ij} \\times (1-w_{ij}) & \\text{if } t^{f}_{j} \\leq t^{f}_{input} \\\\\n",
    "a_r^- \\times w_{ij} \\times (1-w_{ij}) &  \\text{if } t^{f}_{j} > t^{f}_{input} \\text{ or $j$ is silent }\\\\ \n",
    "\\end{cases}$$\n",
    "\n",
    "If punishment:\n",
    "$$\n",
    "\\Delta w_{ij} = \n",
    "\\begin{cases}\n",
    "a_p^+ \\times w_{ij} \\times (1-w_{ij}) &  \\text{if } t^{f}_{j} > t^{f}_{input} \\text{ or $j$ is silent }\\\\ \n",
    "a_p^- \\times w_{ij} \\times (1-w_{ij}) & \\text{if } t^{f}_{j} \\leq t^{f}_{input} \\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "  \n",
    "**If none of the neurons in the grids fire, no reward/punishment signal is generated and thus no weight change is applied.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_RSTDP(synaptic_weights, pre_spiked_before_post, reward, Ar_plus, Ar_neg, Ap_plus, Ap_neg):\n",
    "    \"\"\"\n",
    "        Expects:\n",
    "            -  synaptic weights from a given grid\n",
    "            - a matrix indicating for each orientation row and column whether there was a spike\n",
    "            in that position firing before the winner spike\n",
    "            - reward or punishment\n",
    "            - parameters for RSTDP\n",
    "    \"\"\"\n",
    "    \n",
    "    # get C1-S2 synapses parameters\n",
    "    n_rows, n_cols = synaptic_weights.shape\n",
    "    \n",
    "    # initialize a container for the delta weights\n",
    "    delta_weights = np.zeros((n_rows, n_cols))\n",
    "    \n",
    "    # for each orientation, row and column (i.e. for each synaptic weight)\n",
    "    for (row, col), w_ij in np.ndenumerate(synaptic_weights):\n",
    "        \n",
    "        logging.info(f'Reward{reward}')\n",
    "        if reward: # apply normal STDP\n",
    "            \n",
    "            if pre_spiked_before_post[row,col]:\n",
    "                # correct decision, helpful neuron, boost weights so it reacts faster next time\n",
    "                delta_weights[row,col] = Ar_plus * synaptic_weights[row,col] * (1-synaptic_weights[row,col])\n",
    "                \n",
    "            else: # spiked after or silent\n",
    "                # correct decision, but not helpful spike, decrease weights ...\n",
    "                delta_weights[row,col] = Ar_neg * synaptic_weights[row,col] * (1-synaptic_weights[row,col])\n",
    "\n",
    "        else: # punishment signal reverses the polarity of STDP\n",
    "\n",
    "            if pre_spiked_before_post[row,col]:\n",
    "                # bad decision, decrease weights so we don't make the mistake next time\n",
    "                delta_weights[row,col] = Ap_neg * synaptic_weights[row,col] * (1-synaptic_weights[row,col])\n",
    "                \n",
    "            else: # spiked after or silent\n",
    "                # bad decision, but increase weights just to be sensitive to something else\n",
    "                delta_weights[row,col] = Ap_plus * synaptic_weights[row,col] * (1-synaptic_weights[row,col])\n",
    "    \n",
    "    return delta_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_update(synaptic_weights, computed_delta_weights, adjustment_factor, small_qty):\n",
    "    \"\"\" \n",
    "        Expects:\n",
    "            - synaptic weights from a given grid\n",
    "            - a delta weights computed with rstdp\n",
    "            - an adjustment factor acting as a learning rate\n",
    "            - a small quantity to keep weights between [small_qty, 1-small_qty]\n",
    "    \"\"\"\n",
    "\n",
    "    synaptic_weights += adjustment_factor * computed_delta_weights\n",
    "\n",
    "    # keep weights between 0 and 1\n",
    "    for (row, col), _ in np.ndenumerate(synaptic_weights):\n",
    "\n",
    "        if synaptic_weights[row, col] >= (1 - small_qty) : \n",
    "            synaptic_weights[row, col] = 1 - small_qty\n",
    "        elif synaptic_weights[row, col] <= 0 : \n",
    "            synaptic_weights[row, col] = 0 + small_qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = NeuronalGrids(a.shape, n_grids=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spike x=0, y=0\n",
      "\t Affected (0, 0), Relative position: x=[0] y=[0]\n",
      "Spike x=4, y=0\n",
      "\t Affected (0, 2), Relative position: x=[2] y=[0]\n",
      "\t Affected (0, 3), Relative position: x=[1] y=[0]\n",
      "\t Affected (0, 4), Relative position: x=[0] y=[0]\n",
      "Spike x=5, y=0\n",
      "\t Affected (0, 3), Relative position: x=[2] y=[0]\n",
      "\t Affected (0, 4), Relative position: x=[1] y=[0]\n",
      "\t Affected (0, 5), Relative position: x=[0] y=[0]\n",
      "Spike x=6, y=0\n",
      "\t Affected (0, 4), Relative position: x=[2] y=[0]\n",
      "\t Affected (0, 5), Relative position: x=[1] y=[0]\n",
      "\t Affected (0, 6), Relative position: x=[0] y=[0]\n",
      "Spike x=10, y=0\n",
      "\t Affected (0, 8), Relative position: x=[2] y=[0]\n",
      "Spike x=0, y=1\n",
      "\t Affected (0, 0), Relative position: x=[0] y=[1]\n",
      "Spike x=1, y=1\n",
      "\t Affected (0, 0), Relative position: x=[1] y=[1]\n",
      "\t Affected (0, 1), Relative position: x=[0] y=[1]\n",
      "Spike x=5, y=1\n",
      "\t Affected (0, 3), Relative position: x=[2] y=[1]\n",
      "\t Affected (0, 4), Relative position: x=[1] y=[1]\n",
      "\t Affected (0, 5), Relative position: x=[0] y=[1]\n",
      "Spike x=9, y=1\n",
      "\t Affected (0, 7), Relative position: x=[2] y=[1]\n",
      "\t Affected (0, 8), Relative position: x=[1] y=[1]\n",
      "Spike x=10, y=1\n",
      "\t Affected (0, 8), Relative position: x=[2] y=[1]\n",
      "Spike x=0, y=2\n",
      "\t Affected (0, 0), Relative position: x=[0] y=[2]\n",
      "Spike x=10, y=2\n",
      "\t Affected (0, 8), Relative position: x=[2] y=[2]\n"
     ]
    }
   ],
   "source": [
    "for (j,i), elem in np.ndenumerate(a.grid):\n",
    "    if elem > 0 : \n",
    "        print(f'Spike x={i}, y={j}')\n",
    "        affected_neurons = ng.sensitive_neurons_to_pos[(j,i)]\n",
    "        for neuron in affected_neurons:\n",
    "            relative_y, relative_x = ng.relative_position(np.array([(i, j, 0)], dtype=spike_dtype), neuron, 3)\n",
    "            print(f'\\t Affected {neuron}, Relative position: x={relative_x} y={relative_y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.365\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "n_iters = 2000\n",
    "# Train\n",
    "for i in range(n_iters):\n",
    "    rand_number = random.random()\n",
    "    if rand_number > 0.5 :\n",
    "        #print(\"\\nProcessing 0\")\n",
    "        pred = ng.process(a.spikes, 0)\n",
    "        correct += int(pred == 0) \n",
    "        logging.info('-'*20 + f'Predicted {pred}, real {0}')\n",
    "    else:\n",
    "        #print(\"\\nProcessing 1\")\n",
    "        pred = ng.process(b.spikes, 1)\n",
    "        correct += int(pred == 1) \n",
    "        logging.info('-'*20 + f'Predicted {pred}, real {1}')\n",
    "    \n",
    "print(f'Accuracy: {correct/(n_iters)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "correct = 0\n",
    "n_iters = 2000\n",
    "for i in range(n_iters):\n",
    "    rand_number = random.random()\n",
    "    if rand_number > 0.5 :\n",
    "        #print(\"\\nProcessing 0\")\n",
    "        pred = ng.predict(a.spikes)\n",
    "        correct += int(pred == 0) \n",
    "        logging.info('-'*20 + f'Predicted {pred}, real {0}')\n",
    "    else:\n",
    "        #print(\"\\nProcessing 1\")\n",
    "        pred = ng.predict(b.spikes)\n",
    "        correct += int(pred == 1) \n",
    "        logging.info('-'*20 + f'Predicted {pred}, real {1}')\n",
    "    \n",
    "print(f'Accuracy: {correct/(n_iters)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(ng.synaptic_weights)):\n",
    "    plt.imshow(ng.synaptic_weights[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29974401, 0.4496994 , 0.98274299],\n",
       "       [0.30387455, 0.98899019, 0.99357771],\n",
       "       [0.38130218, 0.50966247, 0.99377217]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng.synaptic_weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.4, 0.2),\n",
       " (0.4, 0.2),\n",
       " (0.4, 0.2),\n",
       " (0.4, 0.2),\n",
       " (0.4, 0.2),\n",
       " (0.4, 0.2),\n",
       " (0.3428571428571429, 0.17142857142857146),\n",
       " (0.30000000000000004, 0.15000000000000002),\n",
       " (0.3111111111111111, 0.15555555555555556),\n",
       " (0.32000000000000006, 0.16000000000000003),\n",
       " (0.32727272727272727, 0.16363636363636364),\n",
       " (0.33333333333333337, 0.16666666666666669),\n",
       " (0.3384615384615385, 0.16923076923076924),\n",
       " (0.3142857142857143, 0.15714285714285714),\n",
       " (0.32000000000000006, 0.16000000000000003),\n",
       " (0.325, 0.1625),\n",
       " (0.3058823529411765, 0.15294117647058825),\n",
       " (0.2888888888888889, 0.14444444444444446),\n",
       " (0.2947368421052632, 0.1473684210526316),\n",
       " (0.30000000000000004, 0.15000000000000002),\n",
       " (0.3047619047619048, 0.1523809523809524),\n",
       " (0.3090909090909091, 0.15454545454545454),\n",
       " (0.3130434782608696, 0.1565217391304348),\n",
       " (0.30000000000000004, 0.15000000000000002),\n",
       " (0.30400000000000005, 0.15200000000000002),\n",
       " (0.3076923076923077, 0.15384615384615385),\n",
       " (0.3111111111111111, 0.15555555555555556),\n",
       " (0.30000000000000004, 0.15000000000000002),\n",
       " (0.30344827586206896, 0.15172413793103448),\n",
       " (0.30666666666666664, 0.15333333333333332),\n",
       " (0.29677419354838713, 0.14838709677419357),\n",
       " (0.28750000000000003, 0.14375000000000002),\n",
       " (0.2787878787878788, 0.1393939393939394),\n",
       " (0.2823529411764706, 0.1411764705882353),\n",
       " (0.28571428571428575, 0.14285714285714288),\n",
       " (0.2777777777777778, 0.1388888888888889),\n",
       " (0.28108108108108104, 0.14054054054054052),\n",
       " (0.28421052631578947, 0.14210526315789473),\n",
       " (0.2871794871794872, 0.1435897435897436),\n",
       " (0.27999999999999997, 0.13999999999999999),\n",
       " (0.28292682926829266, 0.14146341463414633),\n",
       " (0.28571428571428575, 0.14285714285714288),\n",
       " (0.2883720930232558, 0.1441860465116279),\n",
       " (0.29090909090909095, 0.14545454545454548),\n",
       " (0.2933333333333334, 0.1466666666666667),\n",
       " (0.2956521739130435, 0.14782608695652175),\n",
       " (0.29787234042553196, 0.14893617021276598),\n",
       " (0.30000000000000004, 0.15000000000000002),\n",
       " (0.3020408163265306, 0.1510204081632653),\n",
       " (0.30400000000000005, 0.15200000000000002),\n",
       " (0.3058823529411765, 0.15294117647058825),\n",
       " (0.3076923076923077, 0.15384615384615385),\n",
       " (0.30188679245283023, 0.15094339622641512),\n",
       " (0.2962962962962963, 0.14814814814814814),\n",
       " (0.29090909090909095, 0.14545454545454548),\n",
       " (0.29285714285714287, 0.14642857142857144),\n",
       " (0.2947368421052632, 0.1473684210526316),\n",
       " (0.29655172413793107, 0.14827586206896554),\n",
       " (0.2983050847457627, 0.14915254237288136),\n",
       " (0.30000000000000004, 0.15000000000000002),\n",
       " (0.3016393442622951, 0.15081967213114755),\n",
       " (0.3032258064516129, 0.15161290322580645),\n",
       " (0.3047619047619048, 0.1523809523809524),\n",
       " (0.30625, 0.153125),\n",
       " (0.3076923076923077, 0.15384615384615385),\n",
       " (0.3090909090909091, 0.15454545454545454),\n",
       " (0.3104477611940299, 0.15522388059701495),\n",
       " (0.31176470588235294, 0.15588235294117647),\n",
       " (0.3130434782608696, 0.1565217391304348),\n",
       " (0.3085714285714286, 0.1542857142857143),\n",
       " (0.3098591549295775, 0.15492957746478875),\n",
       " (0.3111111111111111, 0.15555555555555556),\n",
       " (0.3123287671232877, 0.15616438356164386),\n",
       " (0.31351351351351353, 0.15675675675675677),\n",
       " (0.31466666666666665, 0.15733333333333333),\n",
       " (0.31578947368421056, 0.15789473684210528),\n",
       " (0.31168831168831174, 0.15584415584415587),\n",
       " (0.3076923076923077, 0.15384615384615385),\n",
       " (0.3088607594936709, 0.15443037974683546),\n",
       " (0.31000000000000005, 0.15500000000000003),\n",
       " (0.3111111111111111, 0.15555555555555556),\n",
       " (0.31219512195121957, 0.15609756097560978),\n",
       " (0.3132530120481928, 0.1566265060240964),\n",
       " (0.3142857142857143, 0.15714285714285714),\n",
       " (0.31529411764705884, 0.15764705882352942),\n",
       " (0.31627906976744186, 0.15813953488372093),\n",
       " (0.31264367816091954, 0.15632183908045977),\n",
       " (0.31363636363636366, 0.15681818181818183),\n",
       " (0.31460674157303375, 0.15730337078651688),\n",
       " (0.3155555555555556, 0.1577777777777778),\n",
       " (0.31648351648351647, 0.15824175824175823),\n",
       " (0.3173913043478261, 0.15869565217391304),\n",
       " (0.31827956989247314, 0.15913978494623657),\n",
       " (0.3148936170212766, 0.1574468085106383),\n",
       " (0.31578947368421056, 0.15789473684210528),\n",
       " (0.3125, 0.15625),\n",
       " (0.3134020618556701, 0.15670103092783505),\n",
       " (0.3142857142857143, 0.15714285714285714),\n",
       " (0.3151515151515152, 0.1575757575757576),\n",
       " (0.31600000000000006, 0.15800000000000003),\n",
       " (0.3168316831683169, 0.15841584158415845),\n",
       " (0.3137254901960784, 0.1568627450980392),\n",
       " (0.31456310679611654, 0.15728155339805827),\n",
       " (0.31153846153846154, 0.15576923076923077),\n",
       " (0.3085714285714286, 0.1542857142857143),\n",
       " (0.309433962264151, 0.1547169811320755),\n",
       " (0.3102803738317757, 0.15514018691588785),\n",
       " (0.3111111111111111, 0.15555555555555556),\n",
       " (0.30825688073394497, 0.15412844036697249),\n",
       " (0.3054545454545455, 0.15272727272727274),\n",
       " (0.3027027027027027, 0.15135135135135136),\n",
       " (0.3035714285714286, 0.1517857142857143),\n",
       " (0.30442477876106194, 0.15221238938053097),\n",
       " (0.3052631578947369, 0.15263157894736845),\n",
       " (0.3060869565217392, 0.1530434782608696),\n",
       " (0.30344827586206896, 0.15172413793103448),\n",
       " (0.3042735042735043, 0.15213675213675215),\n",
       " (0.3050847457627119, 0.15254237288135594),\n",
       " (0.3058823529411765, 0.15294117647058825),\n",
       " (0.30666666666666664, 0.15333333333333332),\n",
       " (0.30743801652892566, 0.15371900826446283),\n",
       " (0.3081967213114754, 0.1540983606557377),\n",
       " (0.3056910569105691, 0.15284552845528454),\n",
       " (0.3064516129032258, 0.1532258064516129),\n",
       " (0.30720000000000003, 0.15360000000000001),\n",
       " (0.3047619047619048, 0.1523809523809524),\n",
       " (0.30236220472440944, 0.15118110236220472),\n",
       " (0.30312500000000003, 0.15156250000000002),\n",
       " (0.30077519379844964, 0.15038759689922482),\n",
       " (0.30153846153846153, 0.15076923076923077),\n",
       " (0.3022900763358779, 0.15114503816793895),\n",
       " (0.30303030303030304, 0.15151515151515152),\n",
       " (0.3037593984962406, 0.1518796992481203),\n",
       " (0.3014925373134329, 0.15074626865671645),\n",
       " (0.2992592592592593, 0.14962962962962964),\n",
       " (0.30000000000000004, 0.15000000000000002),\n",
       " (0.3007299270072993, 0.15036496350364964),\n",
       " (0.30144927536231886, 0.15072463768115943),\n",
       " (0.2992805755395684, 0.1496402877697842),\n",
       " (0.30000000000000004, 0.15000000000000002),\n",
       " (0.300709219858156, 0.150354609929078),\n",
       " (0.29859154929577464, 0.14929577464788732),\n",
       " (0.2993006993006993, 0.14965034965034965),\n",
       " (0.30000000000000004, 0.15000000000000002),\n",
       " (0.2979310344827586, 0.1489655172413793),\n",
       " (0.29863013698630136, 0.14931506849315068),\n",
       " (0.29931972789115646, 0.14965986394557823),\n",
       " (0.30000000000000004, 0.15000000000000002),\n",
       " (0.30067114093959735, 0.15033557046979867),\n",
       " (0.30133333333333334, 0.15066666666666667),\n",
       " (0.3019867549668874, 0.1509933774834437),\n",
       " (0.3026315789473684, 0.1513157894736842),\n",
       " (0.3032679738562092, 0.1516339869281046),\n",
       " (0.3038961038961039, 0.15194805194805194),\n",
       " (0.30451612903225805, 0.15225806451612903),\n",
       " (0.30512820512820515, 0.15256410256410258),\n",
       " (0.30573248407643316, 0.15286624203821658),\n",
       " (0.30632911392405066, 0.15316455696202533),\n",
       " (0.30691823899371073, 0.15345911949685537),\n",
       " (0.30750000000000005, 0.15375000000000003),\n",
       " (0.3055900621118013, 0.15279503105590064),\n",
       " (0.3061728395061729, 0.15308641975308646),\n",
       " (0.3067484662576687, 0.15337423312883436),\n",
       " (0.30487804878048785, 0.15243902439024393),\n",
       " (0.3054545454545455, 0.15272727272727274),\n",
       " (0.30361445783132535, 0.15180722891566267),\n",
       " (0.3041916167664671, 0.15209580838323356),\n",
       " (0.3047619047619048, 0.1523809523809524),\n",
       " (0.3029585798816568, 0.1514792899408284),\n",
       " (0.3011764705882353, 0.15058823529411766),\n",
       " (0.30175438596491233, 0.15087719298245617),\n",
       " (0.3023255813953489, 0.15116279069767444),\n",
       " (0.30289017341040464, 0.15144508670520232),\n",
       " (0.30344827586206896, 0.15172413793103448),\n",
       " (0.30400000000000005, 0.15200000000000002),\n",
       " (0.30454545454545456, 0.15227272727272728),\n",
       " (0.3050847457627119, 0.15254237288135594),\n",
       " (0.3056179775280899, 0.15280898876404495),\n",
       " (0.30614525139664805, 0.15307262569832403),\n",
       " (0.30666666666666664, 0.15333333333333332),\n",
       " (0.30497237569060776, 0.15248618784530388),\n",
       " (0.3054945054945055, 0.15274725274725276),\n",
       " (0.30601092896174864, 0.15300546448087432),\n",
       " (0.30434782608695654, 0.15217391304347827),\n",
       " (0.30486486486486486, 0.15243243243243243),\n",
       " (0.3032258064516129, 0.15161290322580645),\n",
       " (0.30160427807486634, 0.15080213903743317),\n",
       " (0.30000000000000004, 0.15000000000000002),\n",
       " (0.3005291005291006, 0.1502645502645503),\n",
       " (0.3010526315789474, 0.1505263157894737),\n",
       " (0.3015706806282723, 0.15078534031413615),\n",
       " (0.30208333333333337, 0.15104166666666669),\n",
       " (0.3005181347150259, 0.15025906735751296),\n",
       " (0.3010309278350516, 0.1505154639175258),\n",
       " (0.2994871794871795, 0.14974358974358976),\n",
       " (0.30000000000000004, 0.15000000000000002),\n",
       " (0.300507614213198, 0.150253807106599),\n",
       " (0.298989898989899, 0.1494949494949495),\n",
       " (0.29949748743718596, 0.14974874371859298),\n",
       " (0.30000000000000004, 0.15000000000000002),\n",
       " (0.29850746268656714, 0.14925373134328357),\n",
       " (0.297029702970297, 0.1485148514851485),\n",
       " (0.2955665024630542, 0.1477832512315271),\n",
       " (0.296078431372549, 0.1480392156862745),\n",
       " (0.2965853658536585, 0.14829268292682926),\n",
       " (0.2970873786407767, 0.14854368932038836),\n",
       " (0.2956521739130435, 0.14782608695652175),\n",
       " (0.29615384615384616, 0.14807692307692308),\n",
       " (0.2947368421052632, 0.1473684210526316),\n",
       " (0.29523809523809524, 0.14761904761904762),\n",
       " (0.2938388625592417, 0.14691943127962084),\n",
       " (0.29245283018867924, 0.14622641509433962),\n",
       " (0.29295774647887324, 0.14647887323943662),\n",
       " (0.29345794392523367, 0.14672897196261683),\n",
       " (0.29395348837209306, 0.14697674418604653),\n",
       " (0.29444444444444445, 0.14722222222222223),\n",
       " (0.29493087557603687, 0.14746543778801843),\n",
       " (0.29541284403669726, 0.14770642201834863),\n",
       " (0.29589041095890417, 0.14794520547945209),\n",
       " (0.2963636363636364, 0.1481818181818182),\n",
       " (0.29683257918552036, 0.14841628959276018),\n",
       " (0.29549549549549553, 0.14774774774774777),\n",
       " (0.29596412556053814, 0.14798206278026907),\n",
       " (0.29642857142857143, 0.14821428571428572),\n",
       " (0.2951111111111111, 0.14755555555555555),\n",
       " (0.29557522123893804, 0.14778761061946902),\n",
       " (0.2960352422907489, 0.14801762114537445),\n",
       " (0.2964912280701754, 0.1482456140350877),\n",
       " (0.2951965065502184, 0.1475982532751092),\n",
       " (0.2956521739130435, 0.14782608695652175),\n",
       " (0.29437229437229434, 0.14718614718614717),\n",
       " (0.29482758620689653, 0.14741379310344827),\n",
       " (0.2952789699570816, 0.1476394849785408),\n",
       " (0.29572649572649573, 0.14786324786324787),\n",
       " (0.294468085106383, 0.1472340425531915),\n",
       " (0.29491525423728815, 0.14745762711864407),\n",
       " (0.29535864978902954, 0.14767932489451477),\n",
       " (0.29411764705882354, 0.14705882352941177),\n",
       " (0.2945606694560669, 0.14728033472803345),\n",
       " (0.29500000000000004, 0.14750000000000002),\n",
       " (0.2954356846473029, 0.14771784232365145),\n",
       " (0.2958677685950413, 0.14793388429752066),\n",
       " (0.2962962962962963, 0.14814814814814814),\n",
       " (0.29508196721311475, 0.14754098360655737),\n",
       " (0.29551020408163264, 0.14775510204081632),\n",
       " (0.29593495934959346, 0.14796747967479673),\n",
       " (0.2947368421052632, 0.1473684210526316),\n",
       " (0.29516129032258065, 0.14758064516129032),\n",
       " (0.2955823293172691, 0.14779116465863454),\n",
       " (0.296, 0.148),\n",
       " (0.2948207171314741, 0.14741035856573706),\n",
       " (0.29523809523809524, 0.14761904761904762),\n",
       " (0.2956521739130435, 0.14782608695652175),\n",
       " (0.29606299212598425, 0.14803149606299212),\n",
       " (0.29647058823529415, 0.14823529411764708),\n",
       " (0.29531250000000003, 0.14765625000000002),\n",
       " (0.29571984435797666, 0.14785992217898833),\n",
       " (0.2961240310077519, 0.14806201550387596),\n",
       " (0.29652509652509657, 0.14826254826254828),\n",
       " (0.29692307692307696, 0.14846153846153848),\n",
       " (0.2973180076628353, 0.14865900383141764),\n",
       " (0.29770992366412213, 0.14885496183206107),\n",
       " (0.2980988593155893, 0.14904942965779466),\n",
       " (0.2984848484848485, 0.14924242424242426),\n",
       " (0.2988679245283019, 0.14943396226415095),\n",
       " (0.29924812030075193, 0.14962406015037596),\n",
       " (0.2981273408239701, 0.14906367041198504),\n",
       " (0.29850746268656714, 0.14925373134328357),\n",
       " (0.29888475836431233, 0.14944237918215617),\n",
       " (0.2992592592592593, 0.14962962962962964),\n",
       " (0.2981549815498155, 0.14907749077490776),\n",
       " (0.2985294117647059, 0.14926470588235294),\n",
       " (0.29743589743589743, 0.14871794871794872),\n",
       " (0.29781021897810217, 0.14890510948905109),\n",
       " (0.2981818181818182, 0.1490909090909091),\n",
       " (0.2971014492753623, 0.14855072463768115),\n",
       " (0.29602888086642604, 0.14801444043321302),\n",
       " (0.29496402877697847, 0.14748201438848924),\n",
       " (0.2953405017921147, 0.14767025089605734),\n",
       " (0.29571428571428576, 0.14785714285714288),\n",
       " (0.2960854092526691, 0.14804270462633454),\n",
       " (0.2950354609929078, 0.1475177304964539),\n",
       " (0.29540636042402824, 0.14770318021201412),\n",
       " (0.29577464788732394, 0.14788732394366197),\n",
       " (0.2947368421052632, 0.1473684210526316),\n",
       " (0.29510489510489507, 0.14755244755244754),\n",
       " (0.2940766550522648, 0.1470383275261324),\n",
       " (0.29305555555555557, 0.14652777777777778),\n",
       " (0.2934256055363322, 0.1467128027681661),\n",
       " (0.29379310344827586, 0.14689655172413793),\n",
       " (0.2927835051546392, 0.1463917525773196),\n",
       " (0.29315068493150687, 0.14657534246575343),\n",
       " (0.29215017064846416, 0.14607508532423208),\n",
       " (0.29251700680272114, 0.14625850340136057),\n",
       " (0.2928813559322034, 0.1464406779661017),\n",
       " (0.29324324324324325, 0.14662162162162162),\n",
       " (0.2936026936026936, 0.1468013468013468),\n",
       " (0.29395973154362415, 0.14697986577181207),\n",
       " (0.2929765886287625, 0.14648829431438126),\n",
       " (0.2933333333333334, 0.1466666666666667),\n",
       " (0.292358803986711, 0.1461794019933555),\n",
       " (0.2913907284768212, 0.1456953642384106),\n",
       " (0.29042904290429045, 0.14521452145214522),\n",
       " (0.28947368421052627, 0.14473684210526314),\n",
       " (0.2898360655737705, 0.14491803278688525),\n",
       " (0.2901960784313726, 0.1450980392156863),\n",
       " (0.29055374592833877, 0.14527687296416938),\n",
       " (0.2896103896103896, 0.1448051948051948),\n",
       " (0.2899676375404531, 0.14498381877022656),\n",
       " (0.28903225806451616, 0.14451612903225808),\n",
       " (0.2881028938906753, 0.14405144694533764),\n",
       " (0.2871794871794872, 0.1435897435897436),\n",
       " (0.28626198083067095, 0.14313099041533547),\n",
       " (0.28662420382165604, 0.14331210191082802),\n",
       " (0.28571428571428575, 0.14285714285714288),\n",
       " (0.28607594936708863, 0.14303797468354432),\n",
       " (0.2864353312302839, 0.14321766561514196),\n",
       " (0.2867924528301887, 0.14339622641509436),\n",
       " (0.28714733542319754, 0.14357366771159877),\n",
       " (0.28625, 0.143125),\n",
       " (0.28660436137071654, 0.14330218068535827),\n",
       " (0.2869565217391305, 0.14347826086956525),\n",
       " (0.2860681114551084, 0.1430340557275542),\n",
       " (0.2864197530864198, 0.1432098765432099),\n",
       " (0.28676923076923083, 0.14338461538461542),\n",
       " (0.28588957055214725, 0.14294478527607363),\n",
       " (0.2850152905198777, 0.14250764525993884),\n",
       " (0.28536585365853656, 0.14268292682926828),\n",
       " (0.28571428571428575, 0.14285714285714288),\n",
       " (0.28484848484848485, 0.14242424242424243),\n",
       " (0.283987915407855, 0.1419939577039275),\n",
       " (0.28433734939759037, 0.14216867469879518),\n",
       " (0.2834834834834835, 0.14174174174174176),\n",
       " (0.2838323353293413, 0.14191616766467066),\n",
       " (0.28417910447761197, 0.14208955223880598),\n",
       " (0.28452380952380957, 0.14226190476190478),\n",
       " (0.2836795252225519, 0.14183976261127595),\n",
       " (0.2828402366863905, 0.14142011834319526),\n",
       " (0.2831858407079646, 0.1415929203539823),\n",
       " (0.28352941176470586, 0.14176470588235293),\n",
       " (0.28269794721407626, 0.14134897360703813),\n",
       " (0.2818713450292398, 0.1409356725146199),\n",
       " (0.28221574344023326, 0.14110787172011663),\n",
       " (0.2825581395348837, 0.14127906976744184),\n",
       " (0.2828985507246377, 0.14144927536231885),\n",
       " (0.2832369942196532, 0.1416184971098266),\n",
       " (0.2835734870317003, 0.14178674351585016),\n",
       " (0.2839080459770115, 0.14195402298850576),\n",
       " (0.2842406876790831, 0.14212034383954156),\n",
       " (0.2845714285714286, 0.1422857142857143),\n",
       " (0.28376068376068375, 0.14188034188034188),\n",
       " (0.28295454545454546, 0.14147727272727273),\n",
       " (0.28328611898017003, 0.14164305949008502),\n",
       " (0.28361581920903955, 0.14180790960451978),\n",
       " (0.28394366197183096, 0.14197183098591548),\n",
       " (0.2842696629213483, 0.14213483146067415),\n",
       " (0.28459383753501405, 0.14229691876750702),\n",
       " (0.2837988826815642, 0.1418994413407821),\n",
       " (0.2841225626740947, 0.14206128133704735),\n",
       " (0.28444444444444444, 0.14222222222222222),\n",
       " (0.2847645429362881, 0.14238227146814406),\n",
       " (0.28508287292817686, 0.14254143646408843),\n",
       " (0.28539944903581266, 0.14269972451790633),\n",
       " (0.28461538461538466, 0.14230769230769233),\n",
       " (0.2838356164383562, 0.1419178082191781),\n",
       " (0.2841530054644809, 0.14207650273224046),\n",
       " (0.2844686648501362, 0.1422343324250681),\n",
       " (0.28369565217391307, 0.14184782608695654),\n",
       " (0.2840108401084011, 0.14200542005420055),\n",
       " (0.28432432432432436, 0.14216216216216218),\n",
       " (0.2846361185983827, 0.14231805929919136),\n",
       " (0.2849462365591398, 0.1424731182795699),\n",
       " (0.2852546916890081, 0.14262734584450404),\n",
       " (0.28556149732620323, 0.14278074866310161),\n",
       " (0.2848, 0.1424),\n",
       " (0.2851063829787234, 0.1425531914893617),\n",
       " (0.2854111405835544, 0.1427055702917772),\n",
       " (0.28465608465608466, 0.14232804232804233),\n",
       " (0.2849604221635884, 0.1424802110817942),\n",
       " (0.28526315789473683, 0.14263157894736841),\n",
       " (0.28556430446194225, 0.14278215223097113),\n",
       " (0.2858638743455497, 0.14293193717277486),\n",
       " (0.28616187989556136, 0.14308093994778068),\n",
       " (0.2854166666666667, 0.14270833333333335),\n",
       " (0.28571428571428575, 0.14285714285714288),\n",
       " (0.2849740932642487, 0.14248704663212436),\n",
       " (0.28423772609819126, 0.14211886304909563),\n",
       " (0.28453608247422685, 0.14226804123711342),\n",
       " (0.28380462724935734, 0.14190231362467867),\n",
       " (0.28410256410256407, 0.14205128205128204),\n",
       " (0.2843989769820972, 0.1421994884910486),\n",
       " (0.28469387755102044, 0.14234693877551022),\n",
       " (0.28498727735368956, 0.14249363867684478),\n",
       " (0.28527918781725886, 0.14263959390862943),\n",
       " (0.28556962025316457, 0.14278481012658228),\n",
       " (0.28484848484848485, 0.14242424242424243),\n",
       " (0.2841309823677582, 0.1420654911838791),\n",
       " (0.28442211055276384, 0.14221105527638192),\n",
       " (0.2847117794486215, 0.14235588972431076),\n",
       " (0.284, 0.142),\n",
       " (0.28428927680798005, 0.14214463840399003),\n",
       " (0.2845771144278607, 0.14228855721393036),\n",
       " (0.2838709677419355, 0.14193548387096774),\n",
       " (0.28415841584158413, 0.14207920792079207),\n",
       " (0.28345679012345676, 0.14172839506172838),\n",
       " (0.2827586206896552, 0.1413793103448276),\n",
       " (0.28304668304668307, 0.14152334152334153),\n",
       " (0.2833333333333333, 0.14166666666666666),\n",
       " (0.2836185819070905, 0.14180929095354525),\n",
       " (0.2839024390243902, 0.1419512195121951),\n",
       " (0.28418491484184916, 0.14209245742092458),\n",
       " (0.283495145631068, 0.141747572815534),\n",
       " (0.28280871670702185, 0.14140435835351092),\n",
       " (0.28309178743961355, 0.14154589371980678),\n",
       " (0.2833734939759036, 0.1416867469879518),\n",
       " (0.2836538461538462, 0.1418269230769231),\n",
       " (0.2839328537170264, 0.1419664268585132),\n",
       " (0.28325358851674637, 0.14162679425837318),\n",
       " (0.2835322195704057, 0.14176610978520285),\n",
       " (0.28285714285714286, 0.14142857142857143),\n",
       " (0.2831353919239905, 0.14156769596199525),\n",
       " (0.28246445497630335, 0.14123222748815167),\n",
       " (0.28274231678487, 0.141371158392435),\n",
       " (0.28207547169811326, 0.14103773584905663),\n",
       " (0.2823529411764706, 0.1411764705882353),\n",
       " (0.28169014084507044, 0.14084507042253522),\n",
       " (0.2819672131147541, 0.14098360655737704),\n",
       " (0.2822429906542056, 0.1411214953271028),\n",
       " (0.28158508158508155, 0.14079254079254078),\n",
       " (0.2818604651162791, 0.14093023255813955),\n",
       " (0.28120649651972157, 0.14060324825986079),\n",
       " (0.2814814814814815, 0.14074074074074075),\n",
       " (0.28175519630484985, 0.14087759815242493),\n",
       " (0.2820276497695852, 0.1410138248847926),\n",
       " (0.28229885057471266, 0.14114942528735633),\n",
       " (0.28165137614678903, 0.14082568807339452),\n",
       " (0.2819221967963387, 0.14096109839816934),\n",
       " (0.2821917808219178, 0.1410958904109589),\n",
       " (0.2824601366742597, 0.14123006833712984),\n",
       " (0.28181818181818186, 0.14090909090909093),\n",
       " (0.28208616780045354, 0.14104308390022677),\n",
       " (0.281447963800905, 0.1407239819004525),\n",
       " (0.28081264108352144, 0.14040632054176072),\n",
       " (0.2801801801801802, 0.1400900900900901),\n",
       " (0.2804494382022472, 0.1402247191011236),\n",
       " (0.2798206278026906, 0.1399103139013453),\n",
       " (0.280089485458613, 0.1400447427293065),\n",
       " (0.2794642857142857, 0.13973214285714286),\n",
       " (0.2797327394209354, 0.1398663697104677),\n",
       " (0.27999999999999997, 0.13999999999999999),\n",
       " (0.27937915742793795, 0.13968957871396898),\n",
       " (0.27964601769911507, 0.13982300884955753),\n",
       " (0.27991169977924946, 0.13995584988962473),\n",
       " (0.27929515418502204, 0.13964757709251102),\n",
       " (0.2795604395604396, 0.1397802197802198),\n",
       " (0.2798245614035088, 0.1399122807017544),\n",
       " (0.2800875273522976, 0.1400437636761488),\n",
       " (0.27947598253275113, 0.13973799126637557),\n",
       " (0.2797385620915033, 0.13986928104575164),\n",
       " (0.27999999999999997, 0.13999999999999999),\n",
       " (0.27939262472885035, 0.13969631236442517),\n",
       " (0.2787878787878788, 0.1393939393939394),\n",
       " (0.27904967602591796, 0.13952483801295898),\n",
       " (0.2793103448275862, 0.1396551724137931),\n",
       " (0.2795698924731183, 0.13978494623655915),\n",
       " (0.2798283261802575, 0.13991416309012875),\n",
       " (0.28008565310492506, 0.14004282655246253),\n",
       " (0.2794871794871795, 0.13974358974358975),\n",
       " (0.27974413646055435, 0.13987206823027717),\n",
       " (0.27999999999999997, 0.13999999999999999),\n",
       " (0.28025477707006374, 0.14012738853503187),\n",
       " (0.2805084745762712, 0.1402542372881356),\n",
       " (0.2799154334038055, 0.13995771670190274),\n",
       " (0.27932489451476794, 0.13966244725738397),\n",
       " (0.2795789473684211, 0.13978947368421055),\n",
       " (0.27983193277310925, 0.13991596638655462),\n",
       " (0.28008385744234804, 0.14004192872117402),\n",
       " (0.28033472803347287, 0.14016736401673643),\n",
       " (0.28058455114822545, 0.14029227557411272),\n",
       " (0.27999999999999997, 0.13999999999999999),\n",
       " (0.28024948024948027, 0.14012474012474013),\n",
       " (0.2804979253112033, 0.14024896265560166),\n",
       " (0.2799171842650104, 0.1399585921325052),\n",
       " (0.2793388429752066, 0.1396694214876033),\n",
       " (0.27876288659793813, 0.13938144329896907),\n",
       " (0.27901234567901234, 0.13950617283950617),\n",
       " (0.27926078028747436, 0.13963039014373718),\n",
       " (0.2795081967213115, 0.13975409836065575),\n",
       " (0.27975460122699386, 0.13987730061349693),\n",
       " (0.27999999999999997, 0.13999999999999999),\n",
       " (0.28024439918533606, 0.14012219959266803),\n",
       " (0.28048780487804875, 0.14024390243902438),\n",
       " (0.28073022312373225, 0.14036511156186612),\n",
       " (0.28016194331983807, 0.14008097165991903),\n",
       " (0.2795959595959596, 0.1397979797979798),\n",
       " (0.2790322580645161, 0.13951612903225805),\n",
       " (0.2784708249496982, 0.1392354124748491),\n",
       " (0.2779116465863454, 0.1389558232931727),\n",
       " (0.2781563126252505, 0.13907815631262524),\n",
       " (0.2776, 0.1388),\n",
       " (0.27784431137724547, 0.13892215568862273),\n",
       " (0.2772908366533865, 0.13864541832669325),\n",
       " (0.2767395626242545, 0.13836978131212724),\n",
       " (0.276984126984127, 0.1384920634920635),\n",
       " (0.2772277227722772, 0.1386138613861386),\n",
       " (0.2766798418972332, 0.1383399209486166),\n",
       " (0.27692307692307694, 0.13846153846153847),\n",
       " (0.27716535433070866, 0.13858267716535433),\n",
       " (0.2774066797642436, 0.1387033398821218),\n",
       " (0.2776470588235294, 0.1388235294117647),\n",
       " (0.2778864970645793, 0.13894324853228965),\n",
       " (0.278125, 0.1390625),\n",
       " (0.27758284600389865, 0.13879142300194933),\n",
       " (0.27782101167315176, 0.13891050583657588),\n",
       " (0.27805825242718446, 0.13902912621359223),\n",
       " (0.27829457364341087, 0.13914728682170543),\n",
       " (0.27852998065764023, 0.13926499032882012),\n",
       " (0.2787644787644788, 0.1393822393822394),\n",
       " (0.2789980732177264, 0.1394990366088632),\n",
       " (0.2792307692307692, 0.1396153846153846),\n",
       " (0.27869481765834936, 0.13934740882917468),\n",
       " (0.27816091954022987, 0.13908045977011493),\n",
       " (0.2783938814531549, 0.13919694072657746),\n",
       " (0.2786259541984733, 0.13931297709923665),\n",
       " (0.2780952380952381, 0.13904761904761906),\n",
       " (0.27832699619771867, 0.13916349809885933),\n",
       " (0.27855787476280836, 0.13927893738140418),\n",
       " (0.2787878787878788, 0.1393939393939394),\n",
       " (0.2790170132325142, 0.1395085066162571),\n",
       " (0.279245283018868, 0.139622641509434),\n",
       " (0.2787193973634651, 0.13935969868173256),\n",
       " (0.27894736842105267, 0.13947368421052633),\n",
       " (0.27842401500938085, 0.13921200750469043),\n",
       " (0.2786516853932584, 0.1393258426966292),\n",
       " (0.27887850467289715, 0.13943925233644858),\n",
       " (0.27835820895522384, 0.13917910447761192),\n",
       " (0.27783985102420855, 0.13891992551210428),\n",
       " (0.27732342007434946, 0.13866171003717473),\n",
       " (0.27755102040816326, 0.13877551020408163),\n",
       " (0.2770370370370371, 0.13851851851851854),\n",
       " (0.27726432532347506, 0.13863216266173753),\n",
       " (0.2767527675276753, 0.13837638376383765),\n",
       " (0.27697974217311233, 0.13848987108655617),\n",
       " (0.2772058823529412, 0.1386029411764706),\n",
       " (0.27743119266055044, 0.13871559633027522),\n",
       " (0.27692307692307694, 0.13846153846153847),\n",
       " (0.2771480804387569, 0.13857404021937844),\n",
       " (0.2773722627737226, 0.1386861313868613),\n",
       " (0.27759562841530055, 0.13879781420765028),\n",
       " (0.27781818181818185, 0.13890909090909093),\n",
       " (0.27803992740471867, 0.13901996370235933),\n",
       " (0.2782608695652174, 0.1391304347826087),\n",
       " (0.2777576853526221, 0.13887884267631104),\n",
       " (0.2779783393501805, 0.13898916967509026),\n",
       " (0.2781981981981982, 0.1390990990990991),\n",
       " (0.27841726618705037, 0.13920863309352519),\n",
       " (0.2786355475763016, 0.1393177737881508),\n",
       " (0.2781362007168459, 0.13906810035842296),\n",
       " (0.2783542039355993, 0.13917710196779964),\n",
       " (0.2785714285714286, 0.1392857142857143),\n",
       " (0.27807486631016043, 0.13903743315508021),\n",
       " (0.2782918149466192, 0.1391459074733096),\n",
       " (0.277797513321492, 0.138898756660746),\n",
       " (0.27801418439716313, 0.13900709219858157),\n",
       " (0.27823008849557523, 0.13911504424778762),\n",
       " (0.2777385159010601, 0.13886925795053004),\n",
       " (0.27724867724867724, 0.13862433862433862),\n",
       " (0.2774647887323944, 0.1387323943661972),\n",
       " (0.2769771528998243, 0.13848857644991214),\n",
       " (0.2764912280701754, 0.1382456140350877),\n",
       " (0.27600700525394045, 0.13800350262697023),\n",
       " (0.27622377622377625, 0.13811188811188813),\n",
       " (0.27574171029668415, 0.13787085514834208),\n",
       " (0.27526132404181186, 0.13763066202090593),\n",
       " (0.27547826086956523, 0.13773913043478261),\n",
       " (0.275, 0.1375),\n",
       " (0.27521663778162914, 0.13760831889081457),\n",
       " (0.2754325259515571, 0.13771626297577855),\n",
       " (0.2756476683937824, 0.1378238341968912),\n",
       " (0.2758620689655173, 0.13793103448275865),\n",
       " (0.27607573149741826, 0.13803786574870913),\n",
       " (0.27628865979381445, 0.13814432989690723),\n",
       " (0.27581475128644944, 0.13790737564322472),\n",
       " (0.27534246575342464, 0.13767123287671232),\n",
       " (0.27555555555555555, 0.13777777777777778),\n",
       " (0.27576791808873724, 0.13788395904436862),\n",
       " (0.27597955706984667, 0.13798977853492334),\n",
       " (0.2761904761904762, 0.1380952380952381),\n",
       " (0.2764006791171477, 0.13820033955857386),\n",
       " (0.27593220338983054, 0.13796610169491527),\n",
       " (0.2754653130287648, 0.1377326565143824),\n",
       " (0.2756756756756757, 0.13783783783783785),\n",
       " (0.27588532883642497, 0.13794266441821249),\n",
       " (0.2760942760942761, 0.13804713804713806),\n",
       " (0.27630252100840336, 0.13815126050420168),\n",
       " (0.276510067114094, 0.138255033557047),\n",
       " (0.27604690117252934, 0.13802345058626467),\n",
       " (0.2762541806020067, 0.13812709030100334),\n",
       " (0.27646076794657765, 0.13823038397328882),\n",
       " (0.27599999999999997, 0.13799999999999998),\n",
       " (0.275540765391015, 0.1377703826955075),\n",
       " (0.2750830564784053, 0.13754152823920265),\n",
       " (0.2752902155887231, 0.13764510779436154),\n",
       " (0.27549668874172184, 0.13774834437086092),\n",
       " (0.275702479338843, 0.1378512396694215),\n",
       " (0.27590759075907595, 0.13795379537953797),\n",
       " (0.27611202635914334, 0.13805601317957167),\n",
       " (0.27631578947368424, 0.13815789473684212),\n",
       " (0.2758620689655173, 0.13793103448275865),\n",
       " (0.2754098360655738, 0.1377049180327869),\n",
       " (0.27561374795417354, 0.13780687397708677),\n",
       " (0.2758169934640523, 0.13790849673202615),\n",
       " (0.27601957585644377, 0.13800978792822188),\n",
       " (0.2762214983713355, 0.13811074918566776),\n",
       " (0.2764227642276423, 0.13821138211382114),\n",
       " (0.2766233766233766, 0.1383116883116883),\n",
       " (0.2768233387358185, 0.13841166936790925),\n",
       " (0.27702265372168283, 0.13851132686084142),\n",
       " (0.277221324717286, 0.138610662358643),\n",
       " (0.2774193548387097, 0.13870967741935486),\n",
       " (0.27697262479871176, 0.13848631239935588),\n",
       " (0.2771704180064309, 0.13858520900321544),\n",
       " (0.27736757624398073, 0.13868378812199036),\n",
       " (0.2775641025641026, 0.1387820512820513),\n",
       " (0.27776, 0.13888),\n",
       " (0.27731629392971247, 0.13865814696485623),\n",
       " (0.27687400318979266, 0.13843700159489633),\n",
       " (0.2770700636942675, 0.13853503184713375),\n",
       " (0.27662957074721783, 0.13831478537360892),\n",
       " (0.2761904761904762, 0.1380952380952381),\n",
       " (0.2763866877971474, 0.1381933438985737),\n",
       " (0.2765822784810127, 0.13829113924050634),\n",
       " (0.27677725118483415, 0.13838862559241707),\n",
       " (0.2769716088328076, 0.1384858044164038),\n",
       " (0.2765354330708662, 0.1382677165354331),\n",
       " (0.2767295597484277, 0.13836477987421386),\n",
       " (0.27629513343799056, 0.13814756671899528),\n",
       " (0.2764890282131662, 0.1382445141065831),\n",
       " (0.27668231611893584, 0.13834115805946792),\n",
       " (0.276875, 0.1384375),\n",
       " (0.2770670826833073, 0.13853354134165366),\n",
       " (0.2772585669781932, 0.1386292834890966),\n",
       " (0.27682737169517885, 0.13841368584758942),\n",
       " (0.2770186335403727, 0.13850931677018635),\n",
       " (0.27720930232558144, 0.13860465116279072),\n",
       " (0.2773993808049536, 0.1386996904024768),\n",
       " (0.2769706336939722, 0.1384853168469861),\n",
       " (0.2771604938271605, 0.13858024691358026),\n",
       " (0.27734976887519264, 0.13867488443759632),\n",
       " (0.2775384615384615, 0.13876923076923076),\n",
       " (0.27772657450076804, 0.13886328725038402),\n",
       " (0.27791411042944786, 0.13895705521472393),\n",
       " (0.27810107197549766, 0.13905053598774883),\n",
       " (0.27767584097859327, 0.13883792048929663),\n",
       " (0.2778625954198473, 0.13893129770992366),\n",
       " (0.2774390243902439, 0.13871951219512196),\n",
       " (0.2776255707762557, 0.13881278538812786),\n",
       " (0.2772036474164134, 0.1386018237082067),\n",
       " (0.2773899848254932, 0.1386949924127466),\n",
       " (0.2775757575757576, 0.1387878787878788),\n",
       " (0.2771558245083207, 0.13857791225416036),\n",
       " (0.2773413897280967, 0.13867069486404834),\n",
       " (0.277526395173454, 0.138763197586727),\n",
       " (0.27710843373493976, 0.13855421686746988),\n",
       " (0.2772932330827068, 0.1386466165413534),\n",
       " (0.2774774774774775, 0.13873873873873874),\n",
       " (0.27766116941529234, 0.13883058470764617),\n",
       " (0.27784431137724547, 0.13892215568862273),\n",
       " (0.27742899850523167, 0.13871449925261584),\n",
       " (0.2776119402985075, 0.13880597014925375),\n",
       " (0.27779433681073024, 0.13889716840536512),\n",
       " (0.2773809523809524, 0.1386904761904762),\n",
       " (0.2775631500742942, 0.1387815750371471),\n",
       " (0.2777448071216617, 0.13887240356083086),\n",
       " (0.2773333333333334, 0.1386666666666667),\n",
       " (0.27751479289940834, 0.13875739644970417),\n",
       " (0.2776957163958641, 0.13884785819793205),\n",
       " (0.27787610619469033, 0.13893805309734517),\n",
       " (0.2780559646539028, 0.1390279823269514),\n",
       " (0.2782352941176471, 0.13911764705882354),\n",
       " (0.2784140969162996, 0.1392070484581498),\n",
       " (0.27859237536656895, 0.13929618768328447),\n",
       " (0.27877013177159593, 0.13938506588579797),\n",
       " (0.27894736842105267, 0.13947368421052633),\n",
       " (0.2785401459854015, 0.13927007299270075),\n",
       " (0.27871720116618076, 0.13935860058309038),\n",
       " (0.27831149927219795, 0.13915574963609897),\n",
       " (0.2779069767441861, 0.13895348837209304),\n",
       " (0.27808417997097246, 0.13904208998548623),\n",
       " (0.2782608695652174, 0.1391304347826087),\n",
       " (0.2784370477568741, 0.13921852387843706),\n",
       " (0.2780346820809249, 0.13901734104046246),\n",
       " (0.2776334776334776, 0.1388167388167388),\n",
       " (0.2772334293948127, 0.13861671469740636),\n",
       " (0.27741007194244605, 0.13870503597122302),\n",
       " (0.2775862068965517, 0.13879310344827586),\n",
       " (0.27776183644189384, 0.13888091822094692),\n",
       " (0.2779369627507164, 0.1389684813753582),\n",
       " (0.27753934191702434, 0.13876967095851217),\n",
       " (0.27714285714285714, 0.13857142857142857),\n",
       " (0.2767475035663338, 0.1383737517831669),\n",
       " (0.2763532763532764, 0.1381766381766382),\n",
       " (0.2765291607396871, 0.13826458036984354),\n",
       " (0.2767045454545455, 0.13835227272727274),\n",
       " (0.2763120567375887, 0.13815602836879434),\n",
       " (0.2764872521246459, 0.13824362606232296),\n",
       " (0.2766619519094767, 0.13833097595473834),\n",
       " (0.2768361581920904, 0.1384180790960452),\n",
       " (0.27700987306064884, 0.13850493653032442),\n",
       " (0.27661971830985915, 0.13830985915492958),\n",
       " (0.2767932489451477, 0.13839662447257384),\n",
       " (0.27640449438202247, 0.13820224719101123),\n",
       " (0.27601683029453017, 0.13800841514726508),\n",
       " (0.2761904761904762, 0.1380952380952381),\n",
       " (0.27636363636363637, 0.13818181818181818),\n",
       " (0.27653631284916197, 0.13826815642458098),\n",
       " (0.2767085076708508, 0.1383542538354254),\n",
       " (0.2763231197771588, 0.1381615598885794),\n",
       " (0.2764951321279555, 0.13824756606397776),\n",
       " (0.27611111111111114, 0.13805555555555557),\n",
       " (0.2757281553398058, 0.1378640776699029),\n",
       " (0.27590027700831027, 0.13795013850415513),\n",
       " (0.2760719225449516, 0.1380359612724758),\n",
       " (0.27624309392265195, 0.13812154696132597),\n",
       " (0.2758620689655173, 0.13793103448275865),\n",
       " (0.2760330578512397, 0.13801652892561986),\n",
       " (0.2762035763411279, 0.13810178817056395),\n",
       " (0.2763736263736264, 0.1381868131868132),\n",
       " (0.2765432098765432, 0.1382716049382716),\n",
       " (0.27616438356164386, 0.13808219178082193),\n",
       " (0.27633378932968533, 0.13816689466484267),\n",
       " (0.27650273224043714, 0.13825136612021857),\n",
       " (0.2766712141882674, 0.1383356070941337),\n",
       " (0.27683923705722074, 0.13841961852861037),\n",
       " (0.2764625850340136, 0.1382312925170068),\n",
       " (0.2766304347826087, 0.13831521739130434),\n",
       " (0.276797829036635, 0.1383989145183175),\n",
       " (0.2764227642276423, 0.13821138211382114),\n",
       " (0.27658998646820027, 0.13829499323410013),\n",
       " (0.27675675675675676, 0.13837837837837838),\n",
       " (0.2763832658569501, 0.13819163292847506),\n",
       " (0.2765498652291105, 0.13827493261455526),\n",
       " (0.27671601615074026, 0.13835800807537013),\n",
       " (0.2768817204301075, 0.13844086021505375),\n",
       " (0.276510067114094, 0.138255033557047),\n",
       " (0.2766756032171582, 0.1383378016085791),\n",
       " (0.27684069611780454, 0.13842034805890227),\n",
       " (0.2770053475935829, 0.13850267379679146),\n",
       " (0.27663551401869163, 0.13831775700934582),\n",
       " (0.2768, 0.1384),\n",
       " (0.27696404793608526, 0.13848202396804263),\n",
       " (0.2765957446808511, 0.13829787234042554),\n",
       " (0.2767596281540505, 0.13837981407702524),\n",
       " (0.2763925729442971, 0.13819628647214854),\n",
       " (0.2760264900662252, 0.1380132450331126),\n",
       " (0.2761904761904762, 0.1380952380952381),\n",
       " (0.27582562747688244, 0.13791281373844122),\n",
       " (0.27598944591029023, 0.13799472295514512),\n",
       " (0.2761528326745718, 0.1380764163372859),\n",
       " (0.27631578947368424, 0.13815789473684212),\n",
       " (0.2764783180026282, 0.1382391590013141),\n",
       " (0.27664041994750654, 0.13832020997375327),\n",
       " (0.2768020969855832, 0.1384010484927916),\n",
       " (0.27696335078534035, 0.13848167539267017),\n",
       " (0.2766013071895425, 0.13830065359477126),\n",
       " (0.27624020887728457, 0.13812010443864228),\n",
       " (0.27640156453715775, 0.13820078226857888),\n",
       " (0.2765625, 0.13828125),\n",
       " (0.27620286085825746, 0.13810143042912873),\n",
       " (0.27636363636363637, 0.13818181818181818),\n",
       " (0.27652399481193257, 0.13826199740596629),\n",
       " (0.2766839378238342, 0.1383419689119171),\n",
       " (0.276843467011643, 0.1384217335058215),\n",
       " (0.27700258397932814, 0.13850129198966407),\n",
       " (0.2766451612903226, 0.1383225806451613),\n",
       " (0.2768041237113402, 0.1384020618556701),\n",
       " (0.27644787644787644, 0.13822393822393822),\n",
       " (0.2766066838046273, 0.13830334190231364),\n",
       " (0.2762516046213094, 0.1381258023106547),\n",
       " (0.2764102564102564, 0.1382051282051282),\n",
       " (0.27605633802816903, 0.13802816901408452),\n",
       " (0.2757033248081841, 0.13785166240409205),\n",
       " (0.2758620689655173, 0.13793103448275865),\n",
       " (0.2760204081632653, 0.13801020408163264),\n",
       " (0.27566878980891724, 0.13783439490445862),\n",
       " (0.27582697201017814, 0.13791348600508907),\n",
       " (0.2754764930114359, 0.13773824650571795),\n",
       " (0.2756345177664975, 0.13781725888324875),\n",
       " (0.2752851711026616, 0.1376425855513308),\n",
       " (0.27544303797468356, 0.13772151898734178),\n",
       " (0.27509481668773705, 0.13754740834386853),\n",
       " (0.27525252525252525, 0.13762626262626262),\n",
       " (0.2754098360655738, 0.1377049180327869),\n",
       " (0.2755667506297229, 0.13778337531486146),\n",
       " (0.27522012578616356, 0.13761006289308178),\n",
       " (0.27537688442211056, 0.13768844221105528),\n",
       " (0.2755332496863237, 0.13776662484316185),\n",
       " (0.27568922305764415, 0.13784461152882208),\n",
       " (0.2758448060075094, 0.1379224030037547),\n",
       " (0.2755, 0.13775),\n",
       " (0.2756554307116105, 0.13782771535580526),\n",
       " (0.27581047381546137, 0.13790523690773068),\n",
       " (0.2759651307596513, 0.13798256537982564),\n",
       " (0.27611940298507465, 0.13805970149253732),\n",
       " (0.275776397515528, 0.137888198757764),\n",
       " (0.27593052109181143, 0.13796526054590572),\n",
       " (0.27608426270136305, 0.13804213135068152),\n",
       " (0.2762376237623762, 0.1381188118811881),\n",
       " (0.27639060568603213, 0.13819530284301607),\n",
       " (0.2765432098765432, 0.1382716049382716),\n",
       " (0.27669543773119604, 0.13834771886559802),\n",
       " (0.2768472906403941, 0.13842364532019705),\n",
       " (0.27699876998769984, 0.13849938499384992),\n",
       " (0.27665847665847665, 0.13832923832923832),\n",
       " (0.27631901840490797, 0.13815950920245398),\n",
       " (0.27598039215686276, 0.13799019607843138),\n",
       " (0.2761321909424725, 0.13806609547123624),\n",
       " (0.2762836185819071, 0.13814180929095354),\n",
       " (0.27643467643467645, 0.13821733821733823),\n",
       " (0.2765853658536585, 0.13829268292682925),\n",
       " (0.2762484774665043, 0.13812423873325216),\n",
       " (0.2759124087591241, 0.13795620437956205),\n",
       " (0.27557715674362093, 0.13778857837181047),\n",
       " (0.2757281553398058, 0.1378640776699029),\n",
       " (0.2758787878787879, 0.13793939393939394),\n",
       " (0.27602905569007263, 0.13801452784503632),\n",
       " (0.2756952841596131, 0.13784764207980654),\n",
       " (0.2758454106280193, 0.13792270531400966),\n",
       " (0.2759951749095296, 0.1379975874547648),\n",
       " (0.276144578313253, 0.1380722891566265),\n",
       " (0.2762936221419976, 0.1381468110709988),\n",
       " (0.27644230769230765, 0.13822115384615383),\n",
       " (0.2765906362545018, 0.1382953181272509),\n",
       " (0.2767386091127098, 0.1383693045563549),\n",
       " (0.27640718562874256, 0.13820359281437128),\n",
       " (0.276555023923445, 0.1382775119617225),\n",
       " (0.27670250896057347, 0.13835125448028673),\n",
       " (0.2763723150357995, 0.13818615751789975),\n",
       " (0.2765196662693683, 0.13825983313468415),\n",
       " (0.27666666666666667, 0.13833333333333334),\n",
       " (0.27681331747919147, 0.13840665873959573),\n",
       " (0.2764845605700713, 0.13824228028503566),\n",
       " (0.2766310794780546, 0.1383155397390273),\n",
       " (0.27677725118483415, 0.13838862559241707),\n",
       " (0.27644970414201187, 0.13822485207100593),\n",
       " (0.2765957446808511, 0.13829787234042554),\n",
       " (0.276741440377804, 0.138370720188902),\n",
       " (0.2768867924528302, 0.1384433962264151),\n",
       " (0.27656065959952886, 0.13828032979976443),\n",
       " (0.2767058823529412, 0.1383529411764706),\n",
       " (0.27685076380728557, 0.13842538190364279),\n",
       " (0.27699530516431925, 0.13849765258215962),\n",
       " (0.27667057444314186, 0.13833528722157093),\n",
       " (0.27681498829039813, 0.13840749414519907),\n",
       " (0.2769590643274854, 0.1384795321637427),\n",
       " (0.2771028037383178, 0.1385514018691589),\n",
       " (0.27724620770128355, 0.13862310385064178),\n",
       " (0.2773892773892774, 0.1386946386946387),\n",
       " (0.27753201396973226, 0.13876600698486613),\n",
       " (0.27767441860465114, 0.13883720930232557),\n",
       " (0.27781649245063883, 0.13890824622531942),\n",
       " (0.27795823665893277, 0.13897911832946638),\n",
       " (0.27809965237543455, 0.13904982618771727),\n",
       " (0.27824074074074073, 0.13912037037037037),\n",
       " (0.27791907514450864, 0.13895953757225432),\n",
       " (0.27759815242494223, 0.13879907621247112),\n",
       " (0.2777393310265283, 0.13886966551326416),\n",
       " (0.27788018433179723, 0.13894009216589862),\n",
       " (0.27802071346375146, 0.13901035673187573),\n",
       " (0.27816091954022987, 0.13908045977011493),\n",
       " (0.27784156142365096, 0.13892078071182548),\n",
       " (0.2779816513761468, 0.1389908256880734),\n",
       " (0.27812142038946164, 0.13906071019473082),\n",
       " (0.2782608695652174, 0.1391304347826087),\n",
       " (0.2784, 0.1392),\n",
       " (0.27808219178082194, 0.13904109589041097),\n",
       " (0.27822120866590655, 0.13911060433295327),\n",
       " (0.2783599088838269, 0.13917995444191344),\n",
       " (0.2784982935153583, 0.13924914675767916),\n",
       " (0.2786363636363636, 0.1393181818181818),\n",
       " (0.2787741203178206, 0.1393870601589103),\n",
       " (0.27891156462585037, 0.13945578231292519),\n",
       " (0.27859569648924126, 0.13929784824462063),\n",
       " (0.27873303167420815, 0.13936651583710408),\n",
       " (0.2784180790960452, 0.1392090395480226),\n",
       " (0.2781038374717833, 0.13905191873589165),\n",
       " (0.27779030439684327, 0.13889515219842163),\n",
       " (0.277927927927928, 0.138963963963964),\n",
       " (0.27761529808773905, 0.13880764904386952),\n",
       " (0.2777528089887641, 0.13887640449438204),\n",
       " (0.2778900112233446, 0.1389450056116723),\n",
       " (0.27757847533632285, 0.13878923766816142),\n",
       " (0.27726763717805153, 0.13863381858902576),\n",
       " (0.27740492170022374, 0.13870246085011187),\n",
       " (0.2775418994413408, 0.1387709497206704),\n",
       " (0.27767857142857144, 0.13883928571428572),\n",
       " (0.2778149386845039, 0.13890746934225195),\n",
       " (0.2779510022271715, 0.13897550111358575),\n",
       " (0.2776418242491658, 0.1388209121245829),\n",
       " (0.2773333333333334, 0.1386666666666667),\n",
       " (0.2770255271920089, 0.13851276359600445),\n",
       " (0.27671840354767185, 0.13835920177383593),\n",
       " (0.27685492801771877, 0.13842746400885939),\n",
       " (0.2769911504424779, 0.13849557522123895),\n",
       " (0.2771270718232044, 0.1385635359116022),\n",
       " (0.2772626931567329, 0.13863134657836645),\n",
       " (0.2773980154355017, 0.13869900771775084),\n",
       " (0.27709251101321586, 0.13854625550660793),\n",
       " (0.2772277227722772, 0.1386138613861386),\n",
       " (0.2773626373626374, 0.1386813186813187),\n",
       " (0.27749725576289797, 0.13874862788144898),\n",
       " (0.2776315789473684, 0.1388157894736842),\n",
       " (0.27776560788608984, 0.13888280394304492),\n",
       " (0.27789934354485774, 0.13894967177242887),\n",
       " (0.2780327868852459, 0.13901639344262295),\n",
       " (0.2781659388646288, 0.1390829694323144),\n",
       " (0.278298800436205, 0.1391494002181025),\n",
       " (0.2784313725490196, 0.1392156862745098),\n",
       " (0.27856365614798695, 0.13928182807399347),\n",
       " (0.278695652173913, 0.1393478260869565),\n",
       " (0.27839305103148754, 0.13919652551574377),\n",
       " (0.27809110629067246, 0.13904555314533623),\n",
       " (0.2782231852654388, 0.1391115926327194),\n",
       " (0.27835497835497836, 0.13917748917748918),\n",
       " (0.2780540540540541, 0.13902702702702704),\n",
       " (0.2777537796976242, 0.1388768898488121),\n",
       " (0.27788565264293424, 0.13894282632146712),\n",
       " (0.27801724137931033, 0.13900862068965517),\n",
       " (0.27814854682454254, 0.13907427341227127),\n",
       " (0.2782795698924731, 0.13913978494623655),\n",
       " (0.27798066595059073, 0.13899033297529537),\n",
       " (0.27811158798283264, 0.13905579399141632),\n",
       " (0.2782422293676313, 0.13912111468381566),\n",
       " (0.278372591006424, 0.139186295503212),\n",
       " (0.27850267379679144, 0.13925133689839572),\n",
       " (0.27863247863247864, 0.13931623931623932),\n",
       " (0.2783351120597652, 0.1391675560298826),\n",
       " (0.27846481876332624, 0.13923240938166312),\n",
       " (0.2781682641107561, 0.13908413205537806),\n",
       " (0.27787234042553194, 0.13893617021276597),\n",
       " (0.277577045696068, 0.138788522848034),\n",
       " (0.2777070063694268, 0.1388535031847134),\n",
       " (0.27783669141039236, 0.13891834570519618),\n",
       " (0.27796610169491526, 0.13898305084745763),\n",
       " (0.2780952380952381, 0.13904761904761906),\n",
       " (0.27822410147991544, 0.13911205073995772),\n",
       " (0.27835269271383317, 0.13917634635691659),\n",
       " (0.27848101265822783, 0.13924050632911392),\n",
       " (0.27860906217070597, 0.13930453108535298),\n",
       " (0.27831578947368424, 0.13915789473684212),\n",
       " (0.2780231335436383, 0.13901156677181914),\n",
       " (0.2777310924369748, 0.1388655462184874),\n",
       " (0.27785939139559285, 0.13892969569779642),\n",
       " (0.2779874213836478, 0.1389937106918239),\n",
       " (0.2776963350785341, 0.13884816753926704),\n",
       " (0.27740585774058574, 0.13870292887029287),\n",
       " (0.27711598746081506, 0.13855799373040753),\n",
       " (0.27724425887265136, 0.13862212943632568),\n",
       " (0.2773722627737226, 0.1386861313868613),\n",
       " (0.2775, 0.13875),\n",
       " (0.27721123829344435, 0.13860561914672218),\n",
       " (0.27733887733887735, 0.13866943866943868),\n",
       " (0.277466251298027, 0.1387331256490135),\n",
       " (0.27759336099585064, 0.13879668049792532),\n",
       " (0.277720207253886, 0.138860103626943),\n",
       " (0.2778467908902692, 0.1389233954451346),\n",
       " (0.27797311271975184, 0.13898655635987592),\n",
       " (0.278099173553719, 0.1390495867768595),\n",
       " (0.27781217750257997, 0.13890608875128999),\n",
       " (0.2779381443298969, 0.13896907216494844),\n",
       " (0.2780638516992791, 0.13903192584963955),\n",
       " (0.2777777777777778, 0.1388888888888889),\n",
       " (0.2779033915724563, 0.13895169578622815),\n",
       " (0.27802874743326494, 0.13901437371663247),\n",
       " (0.27774358974358976, 0.13887179487179488),\n",
       " (0.27786885245901644, 0.13893442622950822),\n",
       " (0.27799385875127947, 0.13899692937563973),\n",
       " (0.2777096114519428, 0.1388548057259714),\n",
       " (0.2778345250255363, 0.13891726251276815),\n",
       " (0.27755102040816326, 0.13877551020408163),\n",
       " (0.27767584097859327, 0.13883792048929663),\n",
       " (0.2778004073319756, 0.1389002036659878),\n",
       " (0.2775178026449644, 0.1387589013224822),\n",
       " (0.27764227642276423, 0.13882113821138212),\n",
       " (0.27776649746192894, 0.13888324873096447),\n",
       " (0.2778904665314402, 0.1389452332657201),\n",
       " (0.27801418439716313, 0.13900709219858157),\n",
       " (0.27813765182186234, 0.13906882591093117),\n",
       " (0.2782608695652174, 0.1391304347826087),\n",
       " (0.27838383838383834, 0.13919191919191917),\n",
       " (0.2785065590312816, 0.1392532795156408),\n",
       " (0.2786290322580645, 0.13931451612903226),\n",
       " (0.2787512588116818, 0.1393756294058409),\n",
       " (0.27887323943661974, 0.13943661971830987),\n",
       " (0.27899497487437186, 0.13949748743718593),\n",
       " (0.27911646586345384, 0.13955823293172692),\n",
       " (0.2792377131394183, 0.13961885656970915),\n",
       " (0.27895791583166335, 0.13947895791583168),\n",
       " (0.27867867867867874, 0.13933933933933937),\n",
       " (0.2784, 0.1392),\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng.dropouts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
