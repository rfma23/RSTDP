{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic R-STDP Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an input for this basic R-STDP example we will give a `11x3` grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_dtype = np.dtype([('x', np.uint8), ('y', np.uint8), ('ts', np.float32)])\n",
    "c1_spike_dtype = np.dtype([('grid', np.uint8), ('y', np.uint8), ('x', np.uint8), ('ts', np.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grid:\n",
    "    \"\"\"\n",
    "        Each grid represents a pixel array with spikes occurring at\n",
    "        a certain location at the given timestamp.\n",
    "    \"\"\"\n",
    "    def __init__(self, xsize, ysize, grid):\n",
    "        self.xsize = xsize\n",
    "        self.ysize = ysize\n",
    "        self.grid = grid\n",
    "        \n",
    "    @classmethod\n",
    "    def get_grid(cls, i):\n",
    "        \"\"\"\n",
    "            Allows easy initialization of a grid\n",
    "        \"\"\"\n",
    "        if i == 0 :\n",
    "            grid = np.array([[0,0,0,0,0,0,0,0,0,0,0],\n",
    "                             [0,0,0,0,0,0,0,0,0,0,0],\n",
    "                             [0,0,0,0,0,0,0,0,0,0,0]],\n",
    "                           dtype=np.float32)\n",
    "        elif i == 1 :\n",
    "            grid = np.array([[1,0,0,0,5,6,7,0,0,0,9],\n",
    "                             [2,3,0,0,0,8,0,0,0,10,11],\n",
    "                             [4,0,0,0,0,0,0,0,0,0,12]],\n",
    "                           dtype=np.float32)\n",
    "            \n",
    "        elif i == 2 :\n",
    "            grid = np.array([[1,0,0,0,9,10,11,0,0,0,5],\n",
    "                             [2,3,0,0,0,12,0,0,0,6,7],\n",
    "                             [4,0,0,0,0,0,0,0,0,0,8]],\n",
    "                           dtype=np.float32)\n",
    "        else:\n",
    "            raise ValueError('Not a supported grid type')\n",
    "            \n",
    "        return cls(11, 3, grid)\n",
    "    \n",
    "    def show(self):\n",
    "        \"\"\"\n",
    "            Prints a visual representation of the grid including \n",
    "            spike's timestamps\n",
    "        \"\"\"\n",
    "        grayscale = (self.grid > 0).astype(int)\n",
    "        for (j, i), value in np.ndenumerate(self.grid):\n",
    "            if value > 0 : plt.text(i, j, int(value))\n",
    "        plt.imshow(grayscale, vmin=-1, vmax =1, cmap='gray')\n",
    "        plt.xticks(range(self.grid.shape[1]), rotation=0)\n",
    "        plt.show()\n",
    "    \n",
    "    @property\n",
    "    def spikes(self):\n",
    "        \"\"\"\n",
    "            Retrieves the grid spikes in a recarray format with\n",
    "            spikes sorted by timestamp\n",
    "        \"\"\"\n",
    "        grid_spikes = []\n",
    "        for (j, i), value in np.ndenumerate(self.grid):\n",
    "             if value > 0 : grid_spikes.append((i, j, value))\n",
    "        np_spikes = np.array(grid_spikes, dtype=spike_dtype)\n",
    "        np_spikes.sort(order='ts')\n",
    "        return np_spikes\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.grid.shape\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.spikes}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = Grid.get_grid(1)\n",
    "a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([( 0, 0,  1.), ( 0, 1,  2.), ( 1, 1,  3.), ( 0, 2,  4.),\n",
       "       ( 4, 0,  5.), ( 5, 0,  6.), ( 6, 0,  7.), ( 5, 1,  8.),\n",
       "       (10, 0,  9.), ( 9, 1, 10.), (10, 1, 11.), (10, 2, 12.)],\n",
       "      dtype=[('x', 'u1'), ('y', 'u1'), ('ts', '<f4')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = Grid.get_grid(2)\n",
    "b.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronal Grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neuronal grid has $n$ integrate-and-fire (IF) neurons with threshold $\\mathcal{T}$. Each neuron receives its inputs from a $\\omega \\times \\omega$ window -- also called the neuron's receptive field (RF) -- through weighted plastic synapses. In order to provide the ability of detecting a particular feature over the entire spatial positions, all the neurons belonging to the same grid share the same weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the arrival of a spike, we compute its relative position to a neuron $(x_r, y_r)$ and we increase the neuron's synaptic potential with the weight of the relative position if the spike is in its receptive field. In other words, the synaptic potential of neuron $i$ at time $t$ is: \n",
    "\n",
    "$$ v_i(t) = v_i(t-1) + \\sum_{(x_r, y_r) \\in {RF}}{w_{(x_r, y_r)} \\cdot \\delta(t-t_{spike}(j)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each neuronal grid detects a feature, the idea is to have multiple grids and associate each grid to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "import itertools \n",
    "import logging\n",
    "#logging.basicConfig(filename='grid_mac.log',\n",
    "                    #format='%(asctime)s | %(levelname)s | %(message)s',\n",
    "                    #level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronalGrids:\n",
    "    def __init__(self, input_grid_shape, neuron_rf=3, n_grids=4):\n",
    "        \n",
    "        self.input_grid_shape = input_grid_shape\n",
    "        self.grid_shape = ((input_grid_shape[0] - neuron_rf + 1),\n",
    "                           (input_grid_shape[1] - neuron_rf + 1))\n",
    "        \n",
    "        self.n_grids = n_grids\n",
    "        self.neuron_rf = neuron_rf\n",
    "        \n",
    "        self.synaptic_weights = self.initialise_weights(n_grids, neuron_rf)\n",
    "        self.neuron_potential = np.zeros((n_grids, *self.grid_shape), dtype=np.float32)\n",
    "        \n",
    "        self.sensitive_neurons_to_pos = self.get_sensitive_neurons()\n",
    "        self.neuron_threshold = 3.2\n",
    "        \n",
    "        self.reset_metrics()\n",
    "        self.Ar_plus = 0.075\n",
    "        self.Ar_neg = -0.05\n",
    "        self.Ap_plus = 0.04\n",
    "        self.Ap_neg = -0.1\n",
    "        \n",
    "        self.dropouts = []\n",
    "        \n",
    "        # to keep weights between [small_qty, 1-small_qty]\n",
    "        self.small_qty = 0.005\n",
    "    \n",
    "    def initialise_weights(self, n_grids, window_size, mu=0.8, sigma=0.05):\n",
    "        \"\"\"\n",
    "            Initialises the grid weights with values sampled from a normal\n",
    "            distribution mathcal{N}(mu, sigma2)\n",
    "        \"\"\"\n",
    "        # extract as many random samples as needed\n",
    "        grid = np.random.normal(mu, sigma, (n_grids, self.neuron_rf, self.neuron_rf))\n",
    "\n",
    "        # return them as a matrix\n",
    "        result = np.reshape(grid, (n_grids, self.neuron_rf, self.neuron_rf))\n",
    "        #result = np.full((n_grids, self.neuron_rf, self.neuron_rf), 0.8)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        self.n_silence = 0\n",
    "        self.n_hit = 0\n",
    "        self.n_miss = 0\n",
    "        self.n_samples = 0\n",
    "                \n",
    "    def get_temporal_winner(self, spikes, dropout=0.2, neuron_dropout=0.1):\n",
    "        \n",
    "        hasFired = False\n",
    "        is_active = np.random.random((self.n_grids))\n",
    "        is_active_neuron = np.random.random((self.grid_shape))\n",
    "        \n",
    "        for spike in spikes:\n",
    "            for grid in range(self.n_grids):\n",
    "                \n",
    "                if is_active[grid] > dropout:\n",
    "                    if not hasFired:\n",
    "\n",
    "                        affected_neurons = self.sensitive_neurons(spike)\n",
    "\n",
    "                        for neuron in affected_neurons:\n",
    "                            \n",
    "                            if is_active_neuron[neuron] > neuron_dropout:\n",
    "                                \n",
    "                                neuron_row, neuron_col = neuron\n",
    "                            \n",
    "                                relative_y, relative_x = self.relative_position(spike, neuron, self.neuron_rf)\n",
    "\n",
    "                                logging.info(f'Processing spike {spike}, Neuron {(neuron_row, neuron_col)}, Grid {grid}' + \\\n",
    "                                         f'Relative Pos {(relative_y, relative_x)}')\n",
    "                            \n",
    "                                self.neuron_potential[grid, neuron_row, neuron_col] += self.synaptic_weights[grid, relative_y, relative_x]\n",
    "\n",
    "                                if self.neuron_potential[grid, neuron_row, neuron_col] > self.neuron_threshold:\n",
    "                                    out_spike = np.array([(grid, neuron_row, neuron_col, spike['ts'])], dtype=c1_spike_dtype)\n",
    "                                    hasFired = True\n",
    "                                    break\n",
    "                                    \n",
    "                            # else ignore neuron\n",
    "\n",
    "                    else: # has fired\n",
    "                        return out_spike[0]\n",
    "                    \n",
    "                # else skip grid\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def predict(self, spikes):\n",
    "        \n",
    "        self.neuron_potential = np.zeros((self.n_grids, *self.grid_shape), dtype=np.float32)\n",
    "        winner_spike = self.get_temporal_winner(spikes, dropout=0, neuron_dropout=0)\n",
    "        \n",
    "        pred_class = None\n",
    "        \n",
    "        # if there is a winner: \n",
    "        if winner_spike is not None:\n",
    "            # get the class prediction of the winner\n",
    "            pred_class = winner_spike['grid'] % 2\n",
    "        \n",
    "        return pred_class\n",
    "        \n",
    "    def process(self, spikes, label, train=True):\n",
    "        \n",
    "        self.neuron_potential = np.zeros((self.n_grids, *self.grid_shape), dtype=np.float32)\n",
    "        \n",
    "        dropout=0.4*(1-self.n_hit/(self.n_samples+1))\n",
    "        neuron_dropout=0.2*(1-self.n_hit/(self.n_samples+1))\n",
    "        \n",
    "        self.dropouts.append((dropout, neuron_dropout))\n",
    "        \n",
    "        winner_spike = self.get_temporal_winner(spikes, dropout, neuron_dropout)\n",
    "        logging.info(winner_spike)\n",
    "        \n",
    "        # there can be no winners (no spikes), by default\n",
    "        reward = False\n",
    "        pred_class = None\n",
    "        \n",
    "        # if there is a winner: \n",
    "        if winner_spike is not None:\n",
    "            \n",
    "            # get the class prediction of the winner\n",
    "            pred_class = winner_spike['grid'] % 2\n",
    "            \n",
    "            # get the corresponding reward:\n",
    "            is_correct = (pred_class == label)\n",
    "            reward = is_correct\n",
    "            \n",
    "            logging.info(f'Reward {reward}, label {label}')\n",
    "            # compute metrics for performance and adjustment factor\n",
    "            self.n_hit += int(is_correct)\n",
    "            self.n_miss += int(is_correct)\n",
    "            \n",
    "            # if in training mode\n",
    "            if train:\n",
    "                # now we should trigger the learning process (only the winner grid updates its weights)\n",
    "                self.synaptic_plasticity(winner_spike, reward, spikes)\n",
    "        \n",
    "        # else there was no winner (silence)\n",
    "        else:\n",
    "            # increase all weights equally to the grids associated to the class\n",
    "            self.synaptic_weights[label] += 0.00005\n",
    "            # consider that for metrics\n",
    "            self.n_silence +=1\n",
    "            \n",
    "            # If none of the C2 neurons fire, no reward/punishment signal is generated, \n",
    "            # and thus, no weight change is applied.\n",
    "            \n",
    "                \n",
    "        # whatever the result, we processed one image\n",
    "        self.n_samples += 1\n",
    "        \n",
    "        return pred_class\n",
    "    \n",
    "    def synaptic_plasticity(self, winner_spike, reward, c1_spikes): \n",
    "        \n",
    "        \n",
    "        # self.synaptic_weights[winner_spike['grid']] contains the weights between C1 and S2, \n",
    "        # for a grid with one weight linking each orientation and (x,y) pixel\n",
    "        \n",
    "        grid_ix = winner_spike['grid']\n",
    "        \n",
    "        #if grid_ix==0: print(f\"Winner spike {winner_spike}, correct {reward}\")\n",
    "        # get whether there was a C1 spike relevant to neuron (in its receptive field)\n",
    "        # which spiked before the S2 spike\n",
    "        spiked_before_post = self.get_whether_pre_spiked_before_post(winner_spike, c1_spikes)\n",
    "        \n",
    "        # compute RSTDP update\n",
    "        computed_delta_weights = compute_RSTDP(self.synaptic_weights[grid_ix], spiked_before_post, reward, self.Ar_plus, self.Ar_neg, self.Ap_plus, self.Ap_neg)\n",
    "        \n",
    "        logging.info(f'Weights {self.synaptic_weights[grid_ix]}, Updates {computed_delta_weights}')\n",
    "        \n",
    "        # perform additive update rule with adaptive learning rate\n",
    "        if reward:\n",
    "            adjustment_factor = (self.n_miss+1)/(self.n_samples+1)\n",
    "        else:\n",
    "            adjustment_factor = (self.n_hit+1)/(self.n_samples+1)\n",
    "        \n",
    "        # apply the updates\n",
    "        apply_update(self.synaptic_weights[grid_ix], computed_delta_weights, adjustment_factor, self.small_qty)\n",
    "        \n",
    "    def relative_position(self, spike, neuron, neuron_rf):\n",
    "        row, col = neuron\n",
    "\n",
    "        relative_row = spike['y'] - row\n",
    "        relative_col = spike['x'] - col\n",
    "\n",
    "        return relative_row, relative_col\n",
    "    \n",
    "    \n",
    "    def get_sensitive_neurons(self):\n",
    "        \n",
    "        sensitive_neurons_to_pos = {}\n",
    "        for y, x in itertools.product(range(self.input_grid_shape[0]), range(self.input_grid_shape[1])) :\n",
    "            sensitive_neurons_to_pos[(y,x)] = []\n",
    "        \n",
    "        #print(sensitive_neurons_to_pos)\n",
    "        for row, col in itertools.product(range(self.grid_shape[0]), range(self.grid_shape[1])):\n",
    "            \n",
    "            neuron_center_row = row + self.neuron_rf//2\n",
    "            neuron_center_col = col + self.neuron_rf//2\n",
    "            \n",
    "            # relevant area for the neuron\n",
    "            row_lb = neuron_center_row-self.neuron_rf//2\n",
    "            row_ub = neuron_center_row+self.neuron_rf//2\n",
    "            col_lb = neuron_center_col-self.neuron_rf//2\n",
    "            col_ub = neuron_center_col+self.neuron_rf//2\n",
    "            \n",
    "            for y, x in itertools.product(range(row_lb, row_ub+1), range(col_lb, col_ub+1)):\n",
    "                sensitive_neurons_to_pos[(y,x)].append((row, col))\n",
    "                \n",
    "        return sensitive_neurons_to_pos\n",
    "                \n",
    "    def sensitive_neurons(self, spike):\n",
    "        return self.sensitive_neurons_to_pos[(spike['y'], spike['x'])]\n",
    "    \n",
    "    def get_whether_pre_spiked_before_post(self, s2_spike, c1_spikes):\n",
    "        \n",
    "        # we first need to understand which are the relevant rows and columns for an S2 neuron\n",
    "        # if a receptive field is 5x5 we have a relevant region in [0:4, 0:4] with center in 2,2\n",
    "        # this neuron centered in 2,2 is the S2 neuron (0,0), therefore:\n",
    "        \n",
    "        pre_spiked_before_post = np.full((self.neuron_rf, self.neuron_rf), False)\n",
    "        \n",
    "        neuron = (s2_spike['y'], s2_spike['x'])\n",
    "        \n",
    "        for spike in c1_spikes:\n",
    "            \n",
    "            #print(f\"Winner spike {s2_spike}, current spike {spike}\")\n",
    "            \n",
    "            if neuron in self.sensitive_neurons(spike):\n",
    "                relative_y, relative_x = self.relative_position(spike, neuron, self.neuron_rf)\n",
    "            \n",
    "                # and it spiked before\n",
    "                if(spike['ts'] <= s2_spike['ts']):\n",
    "                    \n",
    "                    #print(f\"Yeah it spiked before and relevant\")\n",
    "                    # we signal true:\n",
    "                    pre_spiked_before_post[relative_y, relative_x] = True\n",
    "                    \n",
    "               # else if silent or spiked later we keep it false\n",
    "            \n",
    "            # if not in receptive field we also keep it false\n",
    "            \n",
    "        return pre_spiked_before_post\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-STDP\n",
    "\n",
    "The weight updates are modulated by a reward/punishment signal which is received according to the correctness/incorrectness of the network's decision. The network's decision is given by the class associated to the grid which contains the first neuron to fire.\n",
    "\n",
    "If reward:\n",
    "$$\\Delta w_{ij} = \n",
    "\\begin{cases}\n",
    "a_r^+ \\times w_{ij} \\times (1-w_{ij}) & \\text{if } t^{f}_{j} \\leq t^{f}_{input} \\\\\n",
    "a_r^- \\times w_{ij} \\times (1-w_{ij}) &  \\text{if } t^{f}_{j} > t^{f}_{input} \\text{ or $j$ is silent }\\\\ \n",
    "\\end{cases}$$\n",
    "\n",
    "If punishment:\n",
    "$$\n",
    "\\Delta w_{ij} = \n",
    "\\begin{cases}\n",
    "a_p^+ \\times w_{ij} \\times (1-w_{ij}) &  \\text{if } t^{f}_{j} > t^{f}_{input} \\text{ or $j$ is silent }\\\\ \n",
    "a_p^- \\times w_{ij} \\times (1-w_{ij}) & \\text{if } t^{f}_{j} \\leq t^{f}_{input} \\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "  \n",
    "**If none of the neurons in the grids fire, no reward/punishment signal is generated and thus no weight change is applied.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_RSTDP(synaptic_weights, pre_spiked_before_post, reward, Ar_plus, Ar_neg, Ap_plus, Ap_neg):\n",
    "    \"\"\"\n",
    "        Expects:\n",
    "            -  synaptic weights from a given grid\n",
    "            - a matrix indicating for each orientation row and column whether there was a spike\n",
    "            in that position firing before the winner spike\n",
    "            - reward or punishment\n",
    "            - parameters for RSTDP\n",
    "    \"\"\"\n",
    "    \n",
    "    # get C1-S2 synapses parameters\n",
    "    n_rows, n_cols = synaptic_weights.shape\n",
    "    \n",
    "    # initialize a container for the delta weights\n",
    "    delta_weights = np.zeros((n_rows, n_cols))\n",
    "    \n",
    "    # for each orientation, row and column (i.e. for each synaptic weight)\n",
    "    for (row, col), w_ij in np.ndenumerate(synaptic_weights):\n",
    "        \n",
    "        logging.info(f'Reward{reward}')\n",
    "        if reward: # apply normal STDP\n",
    "            \n",
    "            if pre_spiked_before_post[row,col]:\n",
    "                # correct decision, helpful neuron, boost weights so it reacts faster next time\n",
    "                delta_weights[row,col] = Ar_plus * synaptic_weights[row,col] * (1-synaptic_weights[row,col])\n",
    "                \n",
    "            else: # spiked after or silent\n",
    "                # correct decision, but not helpful spike, decrease weights ...\n",
    "                delta_weights[row,col] = Ar_neg * synaptic_weights[row,col] * (1-synaptic_weights[row,col])\n",
    "\n",
    "        else: # punishment signal reverses the polarity of STDP\n",
    "\n",
    "            if pre_spiked_before_post[row,col]:\n",
    "                # bad decision, decrease weights so we don't make the mistake next time\n",
    "                delta_weights[row,col] = Ap_neg * synaptic_weights[row,col] * (1-synaptic_weights[row,col])\n",
    "                \n",
    "            else: # spiked after or silent\n",
    "                # bad decision, but increase weights just to be sensitive to something else\n",
    "                delta_weights[row,col] = Ap_plus * synaptic_weights[row,col] * (1-synaptic_weights[row,col])\n",
    "    \n",
    "    return delta_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_update(synaptic_weights, computed_delta_weights, adjustment_factor, small_qty):\n",
    "    \"\"\" \n",
    "        Expects:\n",
    "            - synaptic weights from a given grid\n",
    "            - a delta weights computed with rstdp\n",
    "            - an adjustment factor acting as a learning rate\n",
    "            - a small quantity to keep weights between [small_qty, 1-small_qty]\n",
    "    \"\"\"\n",
    "\n",
    "    synaptic_weights += adjustment_factor * computed_delta_weights\n",
    "\n",
    "    # keep weights between 0 and 1\n",
    "    for (row, col), _ in np.ndenumerate(synaptic_weights):\n",
    "\n",
    "        if synaptic_weights[row, col] >= (1 - small_qty) : \n",
    "            synaptic_weights[row, col] = 1 - small_qty\n",
    "        elif synaptic_weights[row, col] <= 0 : \n",
    "            synaptic_weights[row, col] = 0 + small_qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = NeuronalGrids(a.shape, n_grids=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spike x=0, y=0\n",
      "\t Affected (0, 0), Relative position: x=[0] y=[0]\n",
      "Spike x=4, y=0\n",
      "\t Affected (0, 2), Relative position: x=[2] y=[0]\n",
      "\t Affected (0, 3), Relative position: x=[1] y=[0]\n",
      "\t Affected (0, 4), Relative position: x=[0] y=[0]\n",
      "Spike x=5, y=0\n",
      "\t Affected (0, 3), Relative position: x=[2] y=[0]\n",
      "\t Affected (0, 4), Relative position: x=[1] y=[0]\n",
      "\t Affected (0, 5), Relative position: x=[0] y=[0]\n",
      "Spike x=6, y=0\n",
      "\t Affected (0, 4), Relative position: x=[2] y=[0]\n",
      "\t Affected (0, 5), Relative position: x=[1] y=[0]\n",
      "\t Affected (0, 6), Relative position: x=[0] y=[0]\n",
      "Spike x=10, y=0\n",
      "\t Affected (0, 8), Relative position: x=[2] y=[0]\n",
      "Spike x=0, y=1\n",
      "\t Affected (0, 0), Relative position: x=[0] y=[1]\n",
      "Spike x=1, y=1\n",
      "\t Affected (0, 0), Relative position: x=[1] y=[1]\n",
      "\t Affected (0, 1), Relative position: x=[0] y=[1]\n",
      "Spike x=5, y=1\n",
      "\t Affected (0, 3), Relative position: x=[2] y=[1]\n",
      "\t Affected (0, 4), Relative position: x=[1] y=[1]\n",
      "\t Affected (0, 5), Relative position: x=[0] y=[1]\n",
      "Spike x=9, y=1\n",
      "\t Affected (0, 7), Relative position: x=[2] y=[1]\n",
      "\t Affected (0, 8), Relative position: x=[1] y=[1]\n",
      "Spike x=10, y=1\n",
      "\t Affected (0, 8), Relative position: x=[2] y=[1]\n",
      "Spike x=0, y=2\n",
      "\t Affected (0, 0), Relative position: x=[0] y=[2]\n",
      "Spike x=10, y=2\n",
      "\t Affected (0, 8), Relative position: x=[2] y=[2]\n"
     ]
    }
   ],
   "source": [
    "for (j,i), elem in np.ndenumerate(a.grid):\n",
    "    if elem > 0 : \n",
    "        print(f'Spike x={i}, y={j}')\n",
    "        affected_neurons = ng.sensitive_neurons_to_pos[(j,i)]\n",
    "        for neuron in affected_neurons:\n",
    "            relative_y, relative_x = ng.relative_position(np.array([(i, j, 0)], dtype=spike_dtype), neuron, 3)\n",
    "            print(f'\\t Affected {neuron}, Relative position: x={relative_x} y={relative_y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6765\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "n_iters = 2000\n",
    "# Train\n",
    "for i in range(n_iters):\n",
    "    rand_number = random.random()\n",
    "    if rand_number > 0.5 :\n",
    "        #print(\"\\nProcessing 0\")\n",
    "        pred = ng.process(a.spikes, 0)\n",
    "        correct += int(pred == 0) \n",
    "        logging.info('-'*20 + f'Predicted {pred}, real {0}')\n",
    "    else:\n",
    "        #print(\"\\nProcessing 1\")\n",
    "        pred = ng.process(b.spikes, 1)\n",
    "        correct += int(pred == 1) \n",
    "        logging.info('-'*20 + f'Predicted {pred}, real {1}')\n",
    "    \n",
    "print(f'Accuracy: {correct/(n_iters)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "correct = 0\n",
    "n_iters = 2000\n",
    "for i in range(n_iters):\n",
    "    rand_number = random.random()\n",
    "    if rand_number > 0.5 :\n",
    "        #print(\"\\nProcessing 0\")\n",
    "        pred = ng.predict(a.spikes)\n",
    "        correct += int(pred == 0) \n",
    "        logging.info('-'*20 + f'Predicted {pred}, real {0}')\n",
    "    else:\n",
    "        #print(\"\\nProcessing 1\")\n",
    "        pred = ng.predict(b.spikes)\n",
    "        correct += int(pred == 1) \n",
    "        logging.info('-'*20 + f'Predicted {pred}, real {1}')\n",
    "    \n",
    "print(f'Accuracy: {correct/(n_iters)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(ng.synaptic_weights)):\n",
    "    plt.imshow(ng.synaptic_weights[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.12422723e-04, 2.12427840e-04, 9.95000000e-01],\n",
       "       [2.12426628e-04, 9.95000000e-01, 9.95000000e-01],\n",
       "       [2.12428121e-04, 2.12427379e-04, 9.95000000e-01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng.synaptic_weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.4, 0.2),\n",
       " (0.4, 0.2),\n",
       " (0.4, 0.2),\n",
       " (0.4, 0.2),\n",
       " (0.4, 0.2),\n",
       " (0.4, 0.2),\n",
       " (0.4, 0.2),\n",
       " (0.35000000000000003, 0.17500000000000002),\n",
       " (0.3111111111111111, 0.15555555555555556),\n",
       " (0.32000000000000006, 0.16000000000000003),\n",
       " (0.32727272727272727, 0.16363636363636364),\n",
       " (0.33333333333333337, 0.16666666666666669),\n",
       " (0.3076923076923077, 0.15384615384615385),\n",
       " (0.3142857142857143, 0.15714285714285714),\n",
       " (0.2933333333333334, 0.1466666666666667),\n",
       " (0.30000000000000004, 0.15000000000000002),\n",
       " (0.2823529411764706, 0.1411764705882353),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.25263157894736843, 0.12631578947368421),\n",
       " (0.26, 0.13),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.27272727272727276, 0.13636363636363638),\n",
       " (0.2608695652173913, 0.13043478260869565),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.27199999999999996, 0.13599999999999998),\n",
       " (0.27692307692307694, 0.13846153846153847),\n",
       " (0.2814814814814815, 0.14074074074074075),\n",
       " (0.28571428571428575, 0.14285714285714288),\n",
       " (0.2758620689655173, 0.13793103448275865),\n",
       " (0.27999999999999997, 0.13999999999999999),\n",
       " (0.2709677419354839, 0.13548387096774195),\n",
       " (0.275, 0.1375),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.2705882352941177, 0.13529411764705884),\n",
       " (0.2742857142857143, 0.13714285714285715),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.2702702702702703, 0.13513513513513514),\n",
       " (0.26315789473684215, 0.13157894736842107),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.27, 0.135),\n",
       " (0.2634146341463414, 0.1317073170731707),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.26976744186046514, 0.13488372093023257),\n",
       " (0.27272727272727276, 0.13636363636363638),\n",
       " (0.27555555555555555, 0.13777777777777778),\n",
       " (0.2782608695652174, 0.1391304347826087),\n",
       " (0.28085106382978725, 0.14042553191489363),\n",
       " (0.275, 0.1375),\n",
       " (0.2693877551020409, 0.13469387755102044),\n",
       " (0.27199999999999996, 0.13599999999999998),\n",
       " (0.27450980392156865, 0.13725490196078433),\n",
       " (0.27692307692307694, 0.13846153846153847),\n",
       " (0.279245283018868, 0.139622641509434),\n",
       " (0.2740740740740741, 0.13703703703703704),\n",
       " (0.27636363636363637, 0.13818181818181818),\n",
       " (0.2785714285714286, 0.1392857142857143),\n",
       " (0.2807017543859649, 0.14035087719298245),\n",
       " (0.2827586206896552, 0.1413793103448276),\n",
       " (0.27796610169491526, 0.13898305084745763),\n",
       " (0.2733333333333334, 0.1366666666666667),\n",
       " (0.2754098360655738, 0.1377049180327869),\n",
       " (0.2709677419354839, 0.13548387096774195),\n",
       " (0.27301587301587305, 0.13650793650793652),\n",
       " (0.275, 0.1375),\n",
       " (0.27692307692307694, 0.13846153846153847),\n",
       " (0.27272727272727276, 0.13636363636363638),\n",
       " (0.2746268656716418, 0.1373134328358209),\n",
       " (0.27647058823529413, 0.13823529411764707),\n",
       " (0.2782608695652174, 0.1391304347826087),\n",
       " (0.27999999999999997, 0.13999999999999999),\n",
       " (0.28169014084507044, 0.14084507042253522),\n",
       " (0.2833333333333333, 0.14166666666666666),\n",
       " (0.28493150684931506, 0.14246575342465753),\n",
       " (0.28108108108108104, 0.14054054054054052),\n",
       " (0.2773333333333334, 0.1386666666666667),\n",
       " (0.2736842105263158, 0.1368421052631579),\n",
       " (0.27012987012987016, 0.13506493506493508),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.26329113924050634, 0.13164556962025317),\n",
       " (0.265, 0.1325),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.26829268292682923, 0.13414634146341461),\n",
       " (0.26987951807228916, 0.13493975903614458),\n",
       " (0.27142857142857146, 0.13571428571428573),\n",
       " (0.27294117647058824, 0.13647058823529412),\n",
       " (0.2744186046511628, 0.1372093023255814),\n",
       " (0.2758620689655173, 0.13793103448275865),\n",
       " (0.2772727272727273, 0.13863636363636364),\n",
       " (0.27415730337078653, 0.13707865168539327),\n",
       " (0.27555555555555555, 0.13777777777777778),\n",
       " (0.27692307692307694, 0.13846153846153847),\n",
       " (0.27391304347826084, 0.13695652173913042),\n",
       " (0.27526881720430113, 0.13763440860215057),\n",
       " (0.2765957446808511, 0.13829787234042554),\n",
       " (0.27789473684210525, 0.13894736842105262),\n",
       " (0.27916666666666673, 0.13958333333333336),\n",
       " (0.27628865979381445, 0.13814432989690723),\n",
       " (0.27755102040816326, 0.13877551020408163),\n",
       " (0.27474747474747474, 0.13737373737373737),\n",
       " (0.27199999999999996, 0.13599999999999998),\n",
       " (0.27326732673267323, 0.13663366336633662),\n",
       " (0.27450980392156865, 0.13725490196078433),\n",
       " (0.2757281553398058, 0.1378640776699029),\n",
       " (0.2730769230769231, 0.13653846153846155),\n",
       " (0.2742857142857143, 0.13714285714285715),\n",
       " (0.27547169811320754, 0.13773584905660377),\n",
       " (0.27289719626168224, 0.13644859813084112),\n",
       " (0.2740740740740741, 0.13703703703703704),\n",
       " (0.27522935779816515, 0.13761467889908258),\n",
       " (0.27636363636363637, 0.13818181818181818),\n",
       " (0.2774774774774775, 0.13873873873873874),\n",
       " (0.275, 0.1375),\n",
       " (0.2725663716814159, 0.13628318584070795),\n",
       " (0.2736842105263158, 0.1368421052631579),\n",
       " (0.2747826086956522, 0.1373913043478261),\n",
       " (0.2758620689655173, 0.13793103448275865),\n",
       " (0.27692307692307694, 0.13846153846153847),\n",
       " (0.2745762711864407, 0.13728813559322034),\n",
       " (0.27563025210084036, 0.13781512605042018),\n",
       " (0.27666666666666667, 0.13833333333333334),\n",
       " (0.27768595041322314, 0.13884297520661157),\n",
       " (0.2754098360655738, 0.1377049180327869),\n",
       " (0.2764227642276423, 0.13821138211382114),\n",
       " (0.2741935483870968, 0.1370967741935484),\n",
       " (0.27199999999999996, 0.13599999999999998),\n",
       " (0.27301587301587305, 0.13650793650793652),\n",
       " (0.2740157480314961, 0.13700787401574804),\n",
       " (0.275, 0.1375),\n",
       " (0.27596899224806204, 0.13798449612403102),\n",
       " (0.27692307692307694, 0.13846153846153847),\n",
       " (0.2778625954198473, 0.13893129770992366),\n",
       " (0.2787878787878788, 0.1393939393939394),\n",
       " (0.2796992481203008, 0.1398496240601504),\n",
       " (0.28059701492537314, 0.14029850746268657),\n",
       " (0.2814814814814815, 0.14074074074074075),\n",
       " (0.27941176470588236, 0.13970588235294118),\n",
       " (0.28029197080291973, 0.14014598540145987),\n",
       " (0.2811594202898551, 0.14057971014492754),\n",
       " (0.2820143884892087, 0.14100719424460434),\n",
       " (0.28285714285714286, 0.14142857142857143),\n",
       " (0.28085106382978725, 0.14042553191489363),\n",
       " (0.28169014084507044, 0.14084507042253522),\n",
       " (0.2825174825174825, 0.14125874125874124),\n",
       " (0.2833333333333333, 0.14166666666666666),\n",
       " (0.28413793103448276, 0.14206896551724138),\n",
       " (0.28493150684931506, 0.14246575342465753),\n",
       " (0.28571428571428575, 0.14285714285714288),\n",
       " (0.2864864864864865, 0.14324324324324325),\n",
       " (0.287248322147651, 0.1436241610738255),\n",
       " (0.288, 0.144),\n",
       " (0.28874172185430463, 0.14437086092715232),\n",
       " (0.28947368421052627, 0.14473684210526314),\n",
       " (0.2901960784313726, 0.1450980392156863),\n",
       " (0.29090909090909095, 0.14545454545454548),\n",
       " (0.28903225806451616, 0.14451612903225808),\n",
       " (0.28974358974358977, 0.14487179487179488),\n",
       " (0.28789808917197457, 0.14394904458598728),\n",
       " (0.28607594936708863, 0.14303797468354432),\n",
       " (0.2867924528301887, 0.14339622641509436),\n",
       " (0.28500000000000003, 0.14250000000000002),\n",
       " (0.28322981366459626, 0.14161490683229813),\n",
       " (0.28395061728395066, 0.14197530864197533),\n",
       " (0.2822085889570552, 0.1411042944785276),\n",
       " (0.28292682926829266, 0.14146341463414633),\n",
       " (0.2812121212121212, 0.1406060606060606),\n",
       " (0.2819277108433735, 0.14096385542168674),\n",
       " (0.28023952095808385, 0.14011976047904193),\n",
       " (0.28095238095238095, 0.14047619047619048),\n",
       " (0.28165680473372784, 0.14082840236686392),\n",
       " (0.27999999999999997, 0.13999999999999999),\n",
       " (0.2807017543859649, 0.14035087719298245),\n",
       " (0.2813953488372093, 0.14069767441860465),\n",
       " (0.28208092485549136, 0.14104046242774568),\n",
       " (0.2827586206896552, 0.1413793103448276),\n",
       " (0.2834285714285715, 0.14171428571428574),\n",
       " (0.2840909090909091, 0.14204545454545456),\n",
       " (0.2824858757062147, 0.14124293785310735),\n",
       " (0.28314606741573034, 0.14157303370786517),\n",
       " (0.2837988826815642, 0.1418994413407821),\n",
       " (0.2822222222222222, 0.1411111111111111),\n",
       " (0.2828729281767956, 0.1414364640883978),\n",
       " (0.2835164835164835, 0.14175824175824175),\n",
       " (0.2841530054644809, 0.14207650273224046),\n",
       " (0.28478260869565214, 0.14239130434782607),\n",
       " (0.28540540540540543, 0.14270270270270272),\n",
       " (0.28602150537634413, 0.14301075268817207),\n",
       " (0.28449197860962566, 0.14224598930481283),\n",
       " (0.2851063829787234, 0.1425531914893617),\n",
       " (0.28571428571428575, 0.14285714285714288),\n",
       " (0.28421052631578947, 0.14210526315789473),\n",
       " (0.2848167539267016, 0.1424083769633508),\n",
       " (0.2833333333333333, 0.14166666666666666),\n",
       " (0.2839378238341969, 0.14196891191709846),\n",
       " (0.28453608247422685, 0.14226804123711342),\n",
       " (0.28512820512820514, 0.14256410256410257),\n",
       " (0.2836734693877551, 0.14183673469387756),\n",
       " (0.28426395939086296, 0.14213197969543148),\n",
       " (0.2828282828282828, 0.1414141414141414),\n",
       " (0.2814070351758794, 0.1407035175879397),\n",
       " (0.28200000000000003, 0.14100000000000001),\n",
       " (0.28059701492537314, 0.14029850746268657),\n",
       " (0.28118811881188116, 0.14059405940594058),\n",
       " (0.27980295566502467, 0.13990147783251233),\n",
       " (0.2803921568627451, 0.14019607843137255),\n",
       " (0.2790243902439024, 0.1395121951219512),\n",
       " (0.2796116504854369, 0.13980582524271845),\n",
       " (0.28019323671497587, 0.14009661835748793),\n",
       " (0.28076923076923077, 0.14038461538461539),\n",
       " (0.2813397129186603, 0.14066985645933014),\n",
       " (0.2819047619047619, 0.14095238095238094),\n",
       " (0.28246445497630335, 0.14123222748815167),\n",
       " (0.2830188679245283, 0.14150943396226415),\n",
       " (0.2835680751173709, 0.14178403755868546),\n",
       " (0.2841121495327103, 0.14205607476635515),\n",
       " (0.2846511627906977, 0.14232558139534884),\n",
       " (0.2833333333333333, 0.14166666666666666),\n",
       " (0.2838709677419355, 0.14193548387096774),\n",
       " (0.28256880733944956, 0.14128440366972478),\n",
       " (0.2812785388127854, 0.1406392694063927),\n",
       " (0.28181818181818186, 0.14090909090909093),\n",
       " (0.28054298642533937, 0.14027149321266968),\n",
       " (0.27927927927927926, 0.13963963963963963),\n",
       " (0.27802690582959644, 0.13901345291479822),\n",
       " (0.2767857142857143, 0.13839285714285715),\n",
       " (0.27555555555555555, 0.13777777777777778),\n",
       " (0.27433628318584075, 0.13716814159292037),\n",
       " (0.27488986784140973, 0.13744493392070486),\n",
       " (0.2754385964912281, 0.13771929824561405),\n",
       " (0.27423580786026197, 0.13711790393013099),\n",
       " (0.2747826086956522, 0.1373913043478261),\n",
       " (0.27532467532467536, 0.13766233766233768),\n",
       " (0.27413793103448275, 0.13706896551724138),\n",
       " (0.27467811158798283, 0.13733905579399142),\n",
       " (0.27350427350427353, 0.13675213675213677),\n",
       " (0.27404255319148935, 0.13702127659574467),\n",
       " (0.2745762711864407, 0.13728813559322034),\n",
       " (0.27341772151898736, 0.13670886075949368),\n",
       " (0.2739495798319328, 0.1369747899159664),\n",
       " (0.2744769874476988, 0.1372384937238494),\n",
       " (0.275, 0.1375),\n",
       " (0.27385892116182575, 0.13692946058091288),\n",
       " (0.27272727272727276, 0.13636363636363638),\n",
       " (0.27325102880658436, 0.13662551440329218),\n",
       " (0.27377049180327867, 0.13688524590163934),\n",
       " (0.2742857142857143, 0.13714285714285715),\n",
       " (0.2747967479674797, 0.13739837398373986),\n",
       " (0.2753036437246964, 0.1376518218623482),\n",
       " (0.27580645161290324, 0.13790322580645162),\n",
       " (0.2763052208835341, 0.13815261044176705),\n",
       " (0.2768, 0.1384),\n",
       " (0.2772908366533865, 0.13864541832669325),\n",
       " (0.2777777777777778, 0.1388888888888889),\n",
       " (0.2782608695652174, 0.1391304347826087),\n",
       " (0.27716535433070866, 0.13858267716535433),\n",
       " (0.276078431372549, 0.1380392156862745),\n",
       " (0.2765625, 0.13828125),\n",
       " (0.27704280155642025, 0.13852140077821012),\n",
       " (0.2775193798449613, 0.13875968992248064),\n",
       " (0.277992277992278, 0.138996138996139),\n",
       " (0.2784615384615385, 0.13923076923076924),\n",
       " (0.27892720306513413, 0.13946360153256707),\n",
       " (0.27938931297709924, 0.13969465648854962),\n",
       " (0.27832699619771867, 0.13916349809885933),\n",
       " (0.2772727272727273, 0.13863636363636364),\n",
       " (0.27622641509433965, 0.13811320754716983),\n",
       " (0.27669172932330827, 0.13834586466165413),\n",
       " (0.27715355805243447, 0.13857677902621723),\n",
       " (0.2776119402985075, 0.13880597014925375),\n",
       " (0.2780669144981413, 0.13903345724907065),\n",
       " (0.27851851851851855, 0.13925925925925928),\n",
       " (0.27749077490774904, 0.13874538745387452),\n",
       " (0.27647058823529413, 0.13823529411764707),\n",
       " (0.27692307692307694, 0.13846153846153847),\n",
       " (0.2759124087591241, 0.13795620437956205),\n",
       " (0.27490909090909094, 0.13745454545454547),\n",
       " (0.27391304347826084, 0.13695652173913042),\n",
       " (0.2743682310469314, 0.1371841155234657),\n",
       " (0.2733812949640288, 0.1366906474820144),\n",
       " (0.2738351254480287, 0.13691756272401434),\n",
       " (0.27285714285714285, 0.13642857142857143),\n",
       " (0.2733096085409253, 0.13665480427046264),\n",
       " (0.2723404255319149, 0.13617021276595745),\n",
       " (0.2713780918727915, 0.13568904593639575),\n",
       " (0.271830985915493, 0.1359154929577465),\n",
       " (0.27228070175438596, 0.13614035087719298),\n",
       " (0.27132867132867133, 0.13566433566433567),\n",
       " (0.27177700348432055, 0.13588850174216027),\n",
       " (0.27222222222222225, 0.13611111111111113),\n",
       " (0.2726643598615917, 0.13633217993079585),\n",
       " (0.2731034482758621, 0.13655172413793104),\n",
       " (0.27353951890034367, 0.13676975945017184),\n",
       " (0.2726027397260274, 0.1363013698630137),\n",
       " (0.27303754266211605, 0.13651877133105803),\n",
       " (0.27346938775510204, 0.13673469387755102),\n",
       " (0.2738983050847458, 0.1369491525423729),\n",
       " (0.272972972972973, 0.1364864864864865),\n",
       " (0.2734006734006734, 0.1367003367003367),\n",
       " (0.2724832214765101, 0.13624161073825505),\n",
       " (0.2729096989966555, 0.13645484949832776),\n",
       " (0.2733333333333334, 0.1366666666666667),\n",
       " (0.2737541528239203, 0.13687707641196015),\n",
       " (0.2728476821192053, 0.13642384105960265),\n",
       " (0.271947194719472, 0.135973597359736),\n",
       " (0.2723684210526316, 0.1361842105263158),\n",
       " (0.2714754098360656, 0.1357377049180328),\n",
       " (0.2705882352941177, 0.13529411764705884),\n",
       " (0.2697068403908795, 0.13485342019543975),\n",
       " (0.2688311688311688, 0.1344155844155844),\n",
       " (0.26925566343042073, 0.13462783171521037),\n",
       " (0.26838709677419353, 0.13419354838709677),\n",
       " (0.267524115755627, 0.1337620578778135),\n",
       " (0.267948717948718, 0.133974358974359),\n",
       " (0.2670926517571885, 0.13354632587859425),\n",
       " (0.26751592356687903, 0.13375796178343952),\n",
       " (0.267936507936508, 0.133968253968254),\n",
       " (0.26708860759493674, 0.13354430379746837),\n",
       " (0.26624605678233443, 0.13312302839116721),\n",
       " (0.26540880503144654, 0.13270440251572327),\n",
       " (0.2658307210031348, 0.1329153605015674),\n",
       " (0.26625000000000004, 0.13312500000000002),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.2658385093167702, 0.1329192546583851),\n",
       " (0.26625386996904027, 0.13312693498452013),\n",
       " (0.2654320987654321, 0.13271604938271606),\n",
       " (0.26584615384615384, 0.13292307692307692),\n",
       " (0.2662576687116564, 0.1331288343558282),\n",
       " (0.2654434250764526, 0.1327217125382263),\n",
       " (0.2658536585365853, 0.13292682926829266),\n",
       " (0.2650455927051672, 0.1325227963525836),\n",
       " (0.2642424242424243, 0.13212121212121214),\n",
       " (0.2646525679758308, 0.1323262839879154),\n",
       " (0.26385542168674697, 0.13192771084337349),\n",
       " (0.26426426426426425, 0.13213213213213212),\n",
       " (0.2634730538922156, 0.1317365269461078),\n",
       " (0.2638805970149254, 0.1319402985074627),\n",
       " (0.2642857142857143, 0.13214285714285715),\n",
       " (0.26350148367952525, 0.13175074183976263),\n",
       " (0.263905325443787, 0.1319526627218935),\n",
       " (0.26430678466076696, 0.13215339233038348),\n",
       " (0.2635294117647059, 0.13176470588235295),\n",
       " (0.2639296187683285, 0.13196480938416424),\n",
       " (0.26432748538011697, 0.13216374269005848),\n",
       " (0.2647230320699709, 0.13236151603498544),\n",
       " (0.26395348837209304, 0.13197674418604652),\n",
       " (0.2643478260869565, 0.13217391304347825),\n",
       " (0.26358381502890177, 0.13179190751445088),\n",
       " (0.2639769452449568, 0.1319884726224784),\n",
       " (0.2632183908045977, 0.13160919540229885),\n",
       " (0.26361031518624645, 0.13180515759312322),\n",
       " (0.26399999999999996, 0.13199999999999998),\n",
       " (0.26438746438746435, 0.13219373219373218),\n",
       " (0.26477272727272727, 0.13238636363636364),\n",
       " (0.2651558073654391, 0.13257790368271954),\n",
       " (0.26440677966101694, 0.13220338983050847),\n",
       " (0.26478873239436623, 0.13239436619718312),\n",
       " (0.2651685393258427, 0.13258426966292136),\n",
       " (0.26554621848739496, 0.13277310924369748),\n",
       " (0.2659217877094972, 0.1329608938547486),\n",
       " (0.2662952646239554, 0.1331476323119777),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.2670360110803324, 0.1335180055401662),\n",
       " (0.2662983425414365, 0.13314917127071824),\n",
       " (0.265564738292011, 0.1327823691460055),\n",
       " (0.265934065934066, 0.132967032967033),\n",
       " (0.2663013698630137, 0.13315068493150686),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.2670299727520436, 0.1335149863760218),\n",
       " (0.2673913043478261, 0.13369565217391305),\n",
       " (0.26775067750677506, 0.13387533875338753),\n",
       " (0.2670270270270271, 0.13351351351351354),\n",
       " (0.26738544474393533, 0.13369272237196766),\n",
       " (0.267741935483871, 0.1338709677419355),\n",
       " (0.2680965147453083, 0.13404825737265416),\n",
       " (0.26737967914438504, 0.13368983957219252),\n",
       " (0.2677333333333333, 0.13386666666666666),\n",
       " (0.2680851063829787, 0.13404255319148936),\n",
       " (0.2673740053050398, 0.1336870026525199),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.2659630606860159, 0.13298153034300794),\n",
       " (0.26631578947368423, 0.13315789473684211),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.26596858638743454, 0.13298429319371727),\n",
       " (0.26631853785900783, 0.13315926892950392),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.26701298701298704, 0.13350649350649352),\n",
       " (0.26735751295336785, 0.13367875647668392),\n",
       " (0.2677002583979328, 0.1338501291989664),\n",
       " (0.2680412371134021, 0.13402061855670105),\n",
       " (0.26735218508997427, 0.13367609254498714),\n",
       " (0.26769230769230773, 0.13384615384615386),\n",
       " (0.2670076726342711, 0.13350383631713555),\n",
       " (0.2663265306122449, 0.13316326530612246),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.267005076142132, 0.133502538071066),\n",
       " (0.26734177215189875, 0.13367088607594937),\n",
       " (0.2676767676767677, 0.13383838383838384),\n",
       " (0.2670025188916877, 0.13350125944584385),\n",
       " (0.2663316582914573, 0.13316582914572864),\n",
       " (0.2666666666666667, 0.13333333333333336),\n",
       " (0.266, 0.133),\n",
       " (0.26533665835411474, 0.13266832917705737),\n",
       " (0.2646766169154229, 0.13233830845771144),\n",
       " (0.26401985111662535, 0.13200992555831267),\n",
       " (0.2643564356435643, 0.13217821782178216),\n",
       " (0.2637037037037037, 0.13185185185185186),\n",
       " (0.26305418719211826, 0.13152709359605913),\n",
       " (0.2633906633906634, 0.1316953316953317),\n",
       " (0.2627450980392157, 0.13137254901960785),\n",
       " (0.263080684596577, 0.1315403422982885),\n",
       " (0.2624390243902439, 0.13121951219512196),\n",
       " (0.26277372262773724, 0.13138686131386862),\n",
       " (0.2631067961165049, 0.13155339805825245),\n",
       " (0.2624697336561743, 0.13123486682808716),\n",
       " (0.26280193236714977, 0.13140096618357489),\n",
       " (0.2621686746987952, 0.1310843373493976),\n",
       " (0.26153846153846155, 0.13076923076923078),\n",
       " (0.26091127098321343, 0.13045563549160671),\n",
       " (0.26028708133971296, 0.13014354066985648),\n",
       " (0.25966587112171835, 0.12983293556085918),\n",
       " (0.259047619047619, 0.1295238095238095),\n",
       " (0.2584323040380047, 0.12921615201900236),\n",
       " (0.2587677725118484, 0.1293838862559242),\n",
       " (0.25910165484633574, 0.12955082742316787),\n",
       " (0.25849056603773585, 0.12924528301886792),\n",
       " (0.2578823529411765, 0.12894117647058825),\n",
       " (0.2572769953051643, 0.12863849765258215),\n",
       " (0.25667447306791574, 0.12833723653395787),\n",
       " (0.2560747663551402, 0.1280373831775701),\n",
       " (0.2564102564102564, 0.1282051282051282),\n",
       " (0.2558139534883721, 0.12790697674418605),\n",
       " (0.2552204176334107, 0.12761020881670534),\n",
       " (0.25462962962962965, 0.12731481481481483),\n",
       " (0.2540415704387991, 0.12702078521939955),\n",
       " (0.2534562211981567, 0.12672811059907835),\n",
       " (0.25287356321839083, 0.12643678160919541),\n",
       " (0.25321100917431194, 0.12660550458715597),\n",
       " (0.25263157894736843, 0.12631578947368421),\n",
       " (0.25205479452054796, 0.12602739726027398),\n",
       " (0.2523917995444191, 0.12619589977220955),\n",
       " (0.25181818181818183, 0.12590909090909091),\n",
       " (0.2512471655328798, 0.1256235827664399),\n",
       " (0.2515837104072398, 0.1257918552036199),\n",
       " (0.2510158013544018, 0.1255079006772009),\n",
       " (0.2504504504504505, 0.12522522522522525),\n",
       " (0.24988764044943823, 0.12494382022471912),\n",
       " (0.2493273542600897, 0.12466367713004485),\n",
       " (0.24966442953020135, 0.12483221476510067),\n",
       " (0.2491071428571429, 0.12455357142857144),\n",
       " (0.24855233853006686, 0.12427616926503343),\n",
       " (0.248, 0.124),\n",
       " (0.24745011086474503, 0.12372505543237251),\n",
       " (0.24778761061946908, 0.12389380530973454),\n",
       " (0.2472406181015453, 0.12362030905077265),\n",
       " (0.24757709251101323, 0.12378854625550662),\n",
       " (0.24791208791208794, 0.12395604395604397),\n",
       " (0.2473684210526316, 0.1236842105263158),\n",
       " (0.24682713347921226, 0.12341356673960613),\n",
       " (0.2462882096069869, 0.12314410480349346),\n",
       " (0.2466230936819172, 0.1233115468409586),\n",
       " (0.24695652173913044, 0.12347826086956522),\n",
       " (0.24642082429501083, 0.12321041214750542),\n",
       " (0.24588744588744593, 0.12294372294372297),\n",
       " (0.2453563714902808, 0.1226781857451404),\n",
       " (0.24482758620689654, 0.12241379310344827),\n",
       " (0.24430107526881725, 0.12215053763440863),\n",
       " (0.24377682403433476, 0.12188841201716738),\n",
       " (0.243254817987152, 0.121627408993576),\n",
       " (0.2435897435897436, 0.1217948717948718),\n",
       " (0.24392324093816634, 0.12196162046908317),\n",
       " (0.24340425531914894, 0.12170212765957447),\n",
       " (0.24288747346072187, 0.12144373673036093),\n",
       " (0.24237288135593218, 0.12118644067796609),\n",
       " (0.24186046511627907, 0.12093023255813953),\n",
       " (0.24135021097046414, 0.12067510548523207),\n",
       " (0.24084210526315789, 0.12042105263157894),\n",
       " (0.24033613445378152, 0.12016806722689076),\n",
       " (0.239832285115304, 0.119916142557652),\n",
       " (0.23933054393305442, 0.11966527196652721),\n",
       " (0.23883089770354907, 0.11941544885177453),\n",
       " (0.23833333333333334, 0.11916666666666667),\n",
       " (0.23866943866943868, 0.11933471933471934),\n",
       " (0.23817427385892118, 0.11908713692946059),\n",
       " (0.23768115942028986, 0.11884057971014493),\n",
       " (0.23801652892561986, 0.11900826446280993),\n",
       " (0.2375257731958763, 0.11876288659793816),\n",
       " (0.23703703703703705, 0.11851851851851852),\n",
       " (0.23655030800821356, 0.11827515400410678),\n",
       " (0.23688524590163934, 0.11844262295081967),\n",
       " (0.2372188139059305, 0.11860940695296525),\n",
       " (0.23673469387755103, 0.11836734693877551),\n",
       " (0.2370672097759674, 0.1185336048879837),\n",
       " (0.23658536585365858, 0.11829268292682929),\n",
       " (0.236105476673428, 0.118052738336714),\n",
       " (0.23643724696356277, 0.11821862348178139),\n",
       " (0.2367676767676768, 0.1183838383838384),\n",
       " (0.23629032258064517, 0.11814516129032258),\n",
       " (0.23661971830985917, 0.11830985915492959),\n",
       " (0.23614457831325303, 0.11807228915662651),\n",
       " (0.2356713426853707, 0.11783567134268536),\n",
       " (0.23520000000000005, 0.11760000000000002),\n",
       " (0.23473053892215567, 0.11736526946107784),\n",
       " (0.2342629482071713, 0.11713147410358565),\n",
       " (0.23459244532803183, 0.11729622266401592),\n",
       " (0.23492063492063495, 0.11746031746031747),\n",
       " (0.2344554455445545, 0.11722772277227725),\n",
       " (0.23478260869565215, 0.11739130434782608),\n",
       " (0.23431952662721894, 0.11715976331360947),\n",
       " (0.23385826771653548, 0.11692913385826774),\n",
       " (0.23418467583497052, 0.11709233791748526),\n",
       " (0.2337254901960784, 0.1168627450980392),\n",
       " (0.23326810176125248, 0.11663405088062624),\n",
       " (0.2328125, 0.11640625),\n",
       " (0.23235867446393765, 0.11617933723196883),\n",
       " (0.2319066147859922, 0.1159533073929961),\n",
       " (0.23223300970873786, 0.11611650485436893),\n",
       " (0.2325581395348837, 0.11627906976744184),\n",
       " (0.23288201160541588, 0.11644100580270794),\n",
       " (0.23243243243243247, 0.11621621621621624),\n",
       " (0.23198458574181116, 0.11599229287090558),\n",
       " (0.23153846153846153, 0.11576923076923076),\n",
       " (0.23186180422264877, 0.11593090211132438),\n",
       " (0.23218390804597702, 0.11609195402298851),\n",
       " (0.23250478011472275, 0.11625239005736138),\n",
       " (0.23206106870229012, 0.11603053435114506),\n",
       " (0.2316190476190476, 0.1158095238095238),\n",
       " (0.23117870722433465, 0.11558935361216732),\n",
       " (0.23074003795066417, 0.11537001897533208),\n",
       " (0.23106060606060608, 0.11553030303030304),\n",
       " (0.23062381852551983, 0.11531190926275992),\n",
       " (0.2309433962264151, 0.11547169811320755),\n",
       " (0.2312617702448211, 0.11563088512241056),\n",
       " (0.23157894736842108, 0.11578947368421054),\n",
       " (0.2318949343339587, 0.11594746716697935),\n",
       " (0.23220973782771537, 0.11610486891385768),\n",
       " (0.23252336448598132, 0.11626168224299066),\n",
       " (0.23208955223880598, 0.11604477611940299),\n",
       " (0.23165735567970205, 0.11582867783985103),\n",
       " (0.23197026022304834, 0.11598513011152417),\n",
       " (0.23153988868274583, 0.11576994434137292),\n",
       " (0.2311111111111111, 0.11555555555555555),\n",
       " (0.23068391866913124, 0.11534195933456562),\n",
       " (0.23099630996309967, 0.11549815498154983),\n",
       " (0.23057090239410682, 0.11528545119705341),\n",
       " (0.23014705882352945, 0.11507352941176473),\n",
       " (0.22972477064220184, 0.11486238532110092),\n",
       " (0.23003663003663002, 0.11501831501831501),\n",
       " (0.2296160877513711, 0.11480804387568555),\n",
       " (0.22919708029197083, 0.11459854014598542),\n",
       " (0.22950819672131148, 0.11475409836065574),\n",
       " (0.2298181818181818, 0.1149090909090909),\n",
       " (0.22940108892921962, 0.11470054446460981),\n",
       " (0.2289855072463768, 0.1144927536231884),\n",
       " (0.22857142857142856, 0.11428571428571428),\n",
       " (0.2288808664259928, 0.1144404332129964),\n",
       " (0.22846846846846847, 0.11423423423423423),\n",
       " (0.22805755395683455, 0.11402877697841728),\n",
       " (0.22764811490125672, 0.11382405745062836),\n",
       " (0.2279569892473118, 0.1139784946236559),\n",
       " (0.22826475849731667, 0.11413237924865834),\n",
       " (0.22857142857142856, 0.11428571428571428),\n",
       " (0.22887700534759362, 0.11443850267379681),\n",
       " (0.22918149466192173, 0.11459074733096086),\n",
       " (0.22877442273534637, 0.11438721136767319),\n",
       " (0.22907801418439722, 0.11453900709219861),\n",
       " (0.22867256637168143, 0.11433628318584071),\n",
       " (0.22826855123674916, 0.11413427561837458),\n",
       " (0.22786596119929456, 0.11393298059964728),\n",
       " (0.2274647887323944, 0.1137323943661972),\n",
       " (0.22706502636203868, 0.11353251318101934),\n",
       " (0.22736842105263158, 0.11368421052631579),\n",
       " (0.22697022767075303, 0.11348511383537652),\n",
       " (0.22727272727272727, 0.11363636363636363),\n",
       " (0.22687609075043633, 0.11343804537521816),\n",
       " (0.22648083623693382, 0.11324041811846691),\n",
       " (0.22608695652173916, 0.11304347826086958),\n",
       " (0.22569444444444448, 0.11284722222222224),\n",
       " (0.22530329289428078, 0.11265164644714039),\n",
       " (0.22560553633217995, 0.11280276816608997),\n",
       " (0.22590673575129536, 0.11295336787564768),\n",
       " (0.2255172413793104, 0.1127586206896552),\n",
       " (0.2251290877796902, 0.1125645438898451),\n",
       " (0.22542955326460482, 0.11271477663230241),\n",
       " (0.22572898799313892, 0.11286449399656946),\n",
       " (0.22534246575342465, 0.11267123287671232),\n",
       " (0.22495726495726498, 0.11247863247863249),\n",
       " (0.22525597269624573, 0.11262798634812286),\n",
       " (0.22487223168654175, 0.11243611584327087),\n",
       " (0.22448979591836737, 0.11224489795918369),\n",
       " (0.22410865874363328, 0.11205432937181664),\n",
       " (0.22372881355932206, 0.11186440677966103),\n",
       " (0.22402707275803724, 0.11201353637901862),\n",
       " (0.22364864864864864, 0.11182432432432432),\n",
       " (0.22327150084317032, 0.11163575042158516),\n",
       " (0.22289562289562292, 0.11144781144781146),\n",
       " (0.22252100840336136, 0.11126050420168068),\n",
       " (0.2221476510067114, 0.1110738255033557),\n",
       " (0.22177554438860972, 0.11088777219430486),\n",
       " (0.22140468227424748, 0.11070234113712374),\n",
       " (0.22103505843071788, 0.11051752921535894),\n",
       " (0.22133333333333335, 0.11066666666666668),\n",
       " (0.22096505823627288, 0.11048252911813644),\n",
       " (0.2205980066445183, 0.11029900332225916),\n",
       " (0.22089552238805973, 0.11044776119402987),\n",
       " (0.2205298013245033, 0.11026490066225166),\n",
       " (0.22016528925619838, 0.11008264462809919),\n",
       " (0.21980198019801983, 0.10990099009900992),\n",
       " (0.22009884678747937, 0.11004942339373969),\n",
       " (0.2197368421052632, 0.1098684210526316),\n",
       " (0.21937602627257802, 0.10968801313628901),\n",
       " (0.219016393442623, 0.1095081967213115),\n",
       " (0.218657937806874, 0.109328968903437),\n",
       " (0.2189542483660131, 0.10947712418300655),\n",
       " (0.21859706362153344, 0.10929853181076672),\n",
       " (0.2182410423452769, 0.10912052117263844),\n",
       " (0.21788617886178863, 0.10894308943089431),\n",
       " (0.21753246753246752, 0.10876623376623376),\n",
       " (0.21782820097244732, 0.10891410048622366),\n",
       " (0.2174757281553398, 0.1087378640776699),\n",
       " (0.21712439418416804, 0.10856219709208402),\n",
       " (0.21741935483870967, 0.10870967741935483),\n",
       " (0.2177133655394525, 0.10885668276972625),\n",
       " (0.21736334405144697, 0.10868167202572349),\n",
       " (0.21765650080256826, 0.10882825040128413),\n",
       " (0.21730769230769234, 0.10865384615384617),\n",
       " (0.21760000000000002, 0.10880000000000001),\n",
       " (0.21725239616613418, 0.10862619808306709),\n",
       " (0.21690590111642744, 0.10845295055821372),\n",
       " (0.21719745222929934, 0.10859872611464967),\n",
       " (0.21685214626391094, 0.10842607313195547),\n",
       " (0.21650793650793654, 0.10825396825396827),\n",
       " (0.2161648177496038, 0.1080824088748019),\n",
       " (0.2158227848101266, 0.1079113924050633),\n",
       " (0.2154818325434439, 0.10774091627172196),\n",
       " (0.21514195583596216, 0.10757097791798108),\n",
       " (0.21543307086614175, 0.10771653543307087),\n",
       " (0.21509433962264152, 0.10754716981132076),\n",
       " (0.21475667189952904, 0.10737833594976452),\n",
       " (0.21442006269592478, 0.10721003134796239),\n",
       " (0.2140845070422535, 0.10704225352112676),\n",
       " (0.21375000000000002, 0.10687500000000001),\n",
       " (0.21341653666146643, 0.10670826833073321),\n",
       " (0.2130841121495327, 0.10654205607476636),\n",
       " (0.21337480559875585, 0.10668740279937793),\n",
       " (0.21304347826086956, 0.10652173913043478),\n",
       " (0.21271317829457362, 0.10635658914728681),\n",
       " (0.21238390092879258, 0.10619195046439629),\n",
       " (0.21267387944358582, 0.10633693972179291),\n",
       " (0.2123456790123457, 0.10617283950617284),\n",
       " (0.21201848998459172, 0.10600924499229586),\n",
       " (0.2123076923076923, 0.10615384615384615),\n",
       " (0.21198156682027652, 0.10599078341013826),\n",
       " (0.2116564417177914, 0.1058282208588957),\n",
       " (0.2113323124042879, 0.10566615620214395),\n",
       " (0.21100917431192664, 0.10550458715596332),\n",
       " (0.21068702290076335, 0.10534351145038168),\n",
       " (0.21036585365853658, 0.10518292682926829),\n",
       " (0.21004566210045664, 0.10502283105022832),\n",
       " (0.20972644376899696, 0.10486322188449848),\n",
       " (0.2094081942336874, 0.1047040971168437),\n",
       " (0.2090909090909091, 0.10454545454545455),\n",
       " (0.2087745839636914, 0.1043872919818457),\n",
       " (0.20845921450151056, 0.10422960725075528),\n",
       " (0.20874811463046755, 0.10437405731523378),\n",
       " (0.20843373493975906, 0.10421686746987953),\n",
       " (0.2081203007518797, 0.10406015037593985),\n",
       " (0.2078078078078078, 0.1039039039039039),\n",
       " (0.20749625187406298, 0.10374812593703149),\n",
       " (0.207185628742515, 0.1035928143712575),\n",
       " (0.20687593423019435, 0.10343796711509717),\n",
       " (0.20656716417910448, 0.10328358208955224),\n",
       " (0.2068554396423249, 0.10342771982116244),\n",
       " (0.2065476190476191, 0.10327380952380955),\n",
       " (0.2062407132243685, 0.10312035661218424),\n",
       " (0.2059347181008902, 0.1029673590504451),\n",
       " (0.20562962962962966, 0.10281481481481483),\n",
       " (0.20532544378698225, 0.10266272189349113),\n",
       " (0.2050221565731167, 0.10251107828655835),\n",
       " (0.2047197640117994, 0.1023598820058997),\n",
       " (0.2044182621502209, 0.10220913107511045),\n",
       " (0.20411764705882351, 0.10205882352941176),\n",
       " (0.20440528634361232, 0.10220264317180616),\n",
       " (0.20469208211143697, 0.10234604105571848),\n",
       " (0.20497803806734993, 0.10248901903367497),\n",
       " (0.20467836257309943, 0.10233918128654972),\n",
       " (0.20437956204379565, 0.10218978102189782),\n",
       " (0.20408163265306123, 0.10204081632653061),\n",
       " (0.20378457059679767, 0.10189228529839883),\n",
       " (0.20348837209302328, 0.10174418604651164),\n",
       " (0.2031930333817126, 0.1015965166908563),\n",
       " (0.2028985507246377, 0.10144927536231885),\n",
       " (0.2031837916063676, 0.1015918958031838),\n",
       " (0.20289017341040463, 0.10144508670520232),\n",
       " (0.20317460317460317, 0.10158730158730159),\n",
       " (0.20345821325648414, 0.10172910662824207),\n",
       " (0.2031654676258993, 0.10158273381294965),\n",
       " (0.2028735632183908, 0.1014367816091954),\n",
       " (0.20258249641319945, 0.10129124820659972),\n",
       " (0.2022922636103152, 0.1011461318051576),\n",
       " (0.20200286123032907, 0.10100143061516453),\n",
       " (0.2017142857142857, 0.10085714285714285),\n",
       " (0.20142653352353782, 0.10071326676176891),\n",
       " (0.20113960113960117, 0.10056980056980058),\n",
       " (0.2008534850640114, 0.1004267425320057),\n",
       " (0.20113636363636367, 0.10056818181818183),\n",
       " (0.20141843971631204, 0.10070921985815602),\n",
       " (0.20169971671388104, 0.10084985835694052),\n",
       " (0.20141442715700145, 0.10070721357850072),\n",
       " (0.20112994350282484, 0.10056497175141242),\n",
       " (0.20084626234132583, 0.10042313117066291),\n",
       " (0.20056338028169016, 0.10028169014084508),\n",
       " (0.20028129395218006, 0.10014064697609003),\n",
       " (0.20056179775280897, 0.10028089887640448),\n",
       " (0.20028050490883592, 0.10014025245441796),\n",
       " (0.20056022408963586, 0.10028011204481793),\n",
       " (0.2002797202797203, 0.10013986013986015),\n",
       " (0.2, 0.1),\n",
       " (0.20027894002789398, 0.10013947001394699),\n",
       " (0.2, 0.1),\n",
       " (0.19972183588317108, 0.09986091794158554),\n",
       " (0.2, 0.1),\n",
       " (0.20027739251040222, 0.10013869625520111),\n",
       " (0.20055401662049863, 0.10027700831024931),\n",
       " (0.2008298755186722, 0.1004149377593361),\n",
       " (0.20055248618784535, 0.10027624309392268),\n",
       " (0.20082758620689659, 0.10041379310344829),\n",
       " (0.20055096418732782, 0.10027548209366391),\n",
       " (0.20082530949105915, 0.10041265474552957),\n",
       " (0.20054945054945056, 0.10027472527472528),\n",
       " (0.20027434842249658, 0.10013717421124829),\n",
       " (0.2, 0.1),\n",
       " (0.20027359781121754, 0.10013679890560877),\n",
       " (0.2, 0.1),\n",
       " (0.19972714870395636, 0.09986357435197818),\n",
       " (0.2, 0.1),\n",
       " (0.19972789115646258, 0.09986394557823129),\n",
       " (0.19945652173913042, 0.09972826086956521),\n",
       " (0.19918588873812754, 0.09959294436906377),\n",
       " (0.19891598915989162, 0.09945799457994581),\n",
       " (0.1986468200270636, 0.0993234100135318),\n",
       " (0.19891891891891894, 0.09945945945945947),\n",
       " (0.1986504723346829, 0.09932523616734144),\n",
       " (0.19892183288409704, 0.09946091644204852),\n",
       " (0.19919246298788695, 0.09959623149394348),\n",
       " (0.19892473118279572, 0.09946236559139786),\n",
       " (0.19919463087248324, 0.09959731543624162),\n",
       " (0.1994638069705094, 0.0997319034852547),\n",
       " (0.19919678714859437, 0.09959839357429719),\n",
       " (0.19893048128342247, 0.09946524064171124),\n",
       " (0.1986648865153538, 0.0993324432576769),\n",
       " (0.19840000000000002, 0.09920000000000001),\n",
       " (0.19866844207723036, 0.09933422103861518),\n",
       " (0.19840425531914893, 0.09920212765957447),\n",
       " (0.19814077025232404, 0.09907038512616202),\n",
       " (0.19787798408488066, 0.09893899204244033),\n",
       " (0.19814569536423843, 0.09907284768211921),\n",
       " (0.19788359788359788, 0.09894179894179894),\n",
       " (0.1976221928665786, 0.0988110964332893),\n",
       " (0.1978891820580475, 0.09894459102902375),\n",
       " (0.19762845849802374, 0.09881422924901187),\n",
       " (0.19789473684210526, 0.09894736842105263),\n",
       " (0.19763469119579502, 0.09881734559789751),\n",
       " (0.19737532808398953, 0.09868766404199476),\n",
       " (0.19764089121887288, 0.09882044560943644),\n",
       " (0.19790575916230368, 0.09895287958115184),\n",
       " (0.19764705882352943, 0.09882352941176471),\n",
       " (0.197911227154047, 0.0989556135770235),\n",
       " (0.19765319426336375, 0.09882659713168188),\n",
       " (0.19791666666666666, 0.09895833333333333),\n",
       " (0.19817945383615088, 0.09908972691807544),\n",
       " (0.19844155844155847, 0.09922077922077924),\n",
       " (0.19870298313878082, 0.09935149156939041),\n",
       " (0.19844559585492227, 0.09922279792746114),\n",
       " (0.19818887451487713, 0.09909443725743856),\n",
       " (0.1979328165374677, 0.09896640826873385),\n",
       " (0.1981935483870968, 0.0990967741935484),\n",
       " (0.1984536082474227, 0.09922680412371135),\n",
       " (0.19819819819819823, 0.09909909909909911),\n",
       " (0.19845758354755785, 0.09922879177377893),\n",
       " (0.1982028241335045, 0.09910141206675226),\n",
       " (0.19794871794871796, 0.09897435897435898),\n",
       " (0.1976952624839949, 0.09884763124199746),\n",
       " (0.19744245524296675, 0.09872122762148337),\n",
       " (0.19770114942528735, 0.09885057471264368),\n",
       " (0.19744897959183674, 0.09872448979591837),\n",
       " (0.19719745222929938, 0.09859872611464969),\n",
       " (0.19745547073791347, 0.09872773536895674),\n",
       " (0.1972045743329098, 0.0986022871664549),\n",
       " (0.1969543147208122, 0.0984771573604061),\n",
       " (0.1967046894803549, 0.09835234474017746),\n",
       " (0.19645569620253164, 0.09822784810126582),\n",
       " (0.19620733249051836, 0.09810366624525918),\n",
       " (0.19646464646464645, 0.09823232323232323),\n",
       " (0.1962168978562421, 0.09810844892812105),\n",
       " (0.19596977329974813, 0.09798488664987406),\n",
       " (0.1957232704402516, 0.0978616352201258),\n",
       " (0.19547738693467337, 0.09773869346733668),\n",
       " (0.19523212045169386, 0.09761606022584693),\n",
       " (0.1954887218045113, 0.09774436090225565),\n",
       " (0.19524405506883605, 0.09762202753441802),\n",
       " (0.19500000000000003, 0.09750000000000002),\n",
       " (0.1947565543071161, 0.09737827715355805),\n",
       " (0.1945137157107232, 0.0972568578553616),\n",
       " (0.19427148194271485, 0.09713574097135742),\n",
       " (0.1945273631840796, 0.0972636815920398),\n",
       " (0.1942857142857143, 0.09714285714285716),\n",
       " (0.19404466501240694, 0.09702233250620347),\n",
       " (0.1942998760842627, 0.09714993804213135),\n",
       " (0.19455445544554456, 0.09727722772277228),\n",
       " (0.1943139678615575, 0.09715698393077875),\n",
       " (0.19407407407407407, 0.09703703703703703),\n",
       " (0.19383477188655981, 0.09691738594327991),\n",
       " (0.1935960591133005, 0.09679802955665025),\n",
       " (0.1933579335793358, 0.0966789667896679),\n",
       " (0.1936117936117936, 0.0968058968058968),\n",
       " (0.19337423312883437, 0.09668711656441718),\n",
       " (0.19362745098039214, 0.09681372549019607),\n",
       " (0.193390452876377, 0.0966952264381885),\n",
       " (0.1936430317848411, 0.09682151589242055),\n",
       " (0.19340659340659339, 0.09670329670329669),\n",
       " (0.19365853658536586, 0.09682926829268293),\n",
       " (0.1934226552984166, 0.0967113276492083),\n",
       " (0.19367396593673966, 0.09683698296836983),\n",
       " (0.19343863912515188, 0.09671931956257594),\n",
       " (0.19368932038834952, 0.09684466019417476),\n",
       " (0.19393939393939397, 0.09696969696969698),\n",
       " (0.1937046004842615, 0.09685230024213075),\n",
       " (0.1939540507859734, 0.0969770253929867),\n",
       " (0.19420289855072467, 0.09710144927536234),\n",
       " (0.19445114595898674, 0.09722557297949337),\n",
       " (0.19421686746987954, 0.09710843373493977),\n",
       " (0.19398315282791817, 0.09699157641395909),\n",
       " (0.19375, 0.096875),\n",
       " (0.1935174069627851, 0.09675870348139255),\n",
       " (0.1932853717026379, 0.09664268585131895),\n",
       " (0.19305389221556887, 0.09652694610778444),\n",
       " (0.19282296650717706, 0.09641148325358853),\n",
       " (0.1930704898446834, 0.0965352449223417),\n",
       " (0.19284009546539382, 0.09642004773269691),\n",
       " (0.19261025029797377, 0.09630512514898688),\n",
       " (0.19285714285714284, 0.09642857142857142),\n",
       " (0.192627824019025, 0.0963139120095125),\n",
       " (0.19239904988123518, 0.09619952494061759),\n",
       " (0.1921708185053381, 0.09608540925266905),\n",
       " (0.19194312796208532, 0.09597156398104266),\n",
       " (0.19218934911242602, 0.09609467455621301),\n",
       " (0.19196217494089837, 0.09598108747044919),\n",
       " (0.19173553719008263, 0.09586776859504131),\n",
       " (0.19150943396226416, 0.09575471698113208),\n",
       " (0.19175500588928152, 0.09587750294464076),\n",
       " (0.19152941176470592, 0.09576470588235296),\n",
       " (0.1917743830787309, 0.09588719153936545),\n",
       " (0.1915492957746479, 0.09577464788732395),\n",
       " (0.19132473622508794, 0.09566236811254397),\n",
       " (0.19110070257611242, 0.09555035128805621),\n",
       " (0.19087719298245617, 0.09543859649122809),\n",
       " (0.19065420560747667, 0.09532710280373834),\n",
       " (0.19043173862310386, 0.09521586931155193),\n",
       " (0.1906759906759907, 0.09533799533799535),\n",
       " (0.19045401629802097, 0.09522700814901049),\n",
       " (0.19069767441860463, 0.09534883720930232),\n",
       " (0.19047619047619047, 0.09523809523809523),\n",
       " (0.19025522041763343, 0.09512761020881672),\n",
       " (0.19049826187717267, 0.09524913093858633),\n",
       " (0.19027777777777777, 0.09513888888888888),\n",
       " (0.19052023121387285, 0.09526011560693642),\n",
       " (0.1903002309468822, 0.0951501154734411),\n",
       " (0.19054209919261825, 0.09527104959630912),\n",
       " (0.1903225806451613, 0.09516129032258065),\n",
       " (0.1901035673187572, 0.0950517836593786),\n",
       " (0.18988505747126438, 0.09494252873563219),\n",
       " (0.18966704936854192, 0.09483352468427096),\n",
       " (0.1894495412844037, 0.09472477064220185),\n",
       " (0.18969072164948453, 0.09484536082474226),\n",
       " (0.18993135011441648, 0.09496567505720824),\n",
       " (0.18971428571428572, 0.09485714285714286),\n",
       " (0.1894977168949772, 0.0947488584474886),\n",
       " (0.18928164196123146, 0.09464082098061573),\n",
       " (0.18906605922551256, 0.09453302961275628),\n",
       " (0.18885096700796358, 0.09442548350398179),\n",
       " (0.18863636363636363, 0.09431818181818181),\n",
       " (0.188422247446084, 0.094211123723042),\n",
       " (0.18820861678004538, 0.09410430839002269),\n",
       " (0.18799546998867497, 0.09399773499433749),\n",
       " (0.18778280542986425, 0.09389140271493213),\n",
       " (0.18757062146892656, 0.09378531073446328),\n",
       " (0.18735891647855532, 0.09367945823927766),\n",
       " (0.1871476888387824, 0.0935738444193912),\n",
       " (0.18693693693693691, 0.09346846846846846),\n",
       " (0.18672665916760406, 0.09336332958380203),\n",
       " (0.1865168539325843, 0.09325842696629215),\n",
       " (0.18675645342312008, 0.09337822671156004),\n",
       " (0.18699551569506725, 0.09349775784753363),\n",
       " (0.18678611422172453, 0.09339305711086227),\n",
       " (0.18657718120805372, 0.09328859060402686),\n",
       " (0.1863687150837989, 0.09318435754189945),\n",
       " (0.1861607142857143, 0.09308035714285715),\n",
       " (0.1859531772575251, 0.09297658862876255),\n",
       " (0.18574610244988865, 0.09287305122494433),\n",
       " (0.18598442714126806, 0.09299221357063403),\n",
       " (0.1862222222222222, 0.0931111111111111),\n",
       " (0.18601553829078804, 0.09300776914539402),\n",
       " (0.18580931263858091, 0.09290465631929046),\n",
       " (0.18560354374307864, 0.09280177187153932),\n",
       " (0.18584070796460175, 0.09292035398230088),\n",
       " (0.18563535911602214, 0.09281767955801107),\n",
       " (0.18543046357615897, 0.09271523178807949),\n",
       " (0.185226019845645, 0.0926130099228225),\n",
       " (0.18502202643171808, 0.09251101321585904),\n",
       " (0.18481848184818483, 0.09240924092409242),\n",
       " (0.18461538461538463, 0.09230769230769231),\n",
       " (0.1844127332601537, 0.09220636663007685),\n",
       " (0.1842105263157895, 0.09210526315789475),\n",
       " (0.18400876232201535, 0.09200438116100768),\n",
       " (0.1842450765864333, 0.09212253829321665),\n",
       " (0.18404371584699453, 0.09202185792349726),\n",
       " (0.18427947598253278, 0.09213973799126639),\n",
       " (0.1845147219193021, 0.09225736095965105),\n",
       " (0.1843137254901961, 0.09215686274509804),\n",
       " (0.18454842219804135, 0.09227421109902068),\n",
       " (0.18434782608695655, 0.09217391304347827),\n",
       " (0.18458197611292074, 0.09229098805646037),\n",
       " (0.18438177874186554, 0.09219088937093277),\n",
       " (0.18418201516793067, 0.09209100758396534),\n",
       " (0.18398268398268403, 0.09199134199134201),\n",
       " (0.1837837837837838, 0.0918918918918919),\n",
       " (0.183585313174946, 0.091792656587473),\n",
       " (0.18381877022653723, 0.09190938511326861),\n",
       " (0.18405172413793106, 0.09202586206896553),\n",
       " (0.1838536060279871, 0.09192680301399354),\n",
       " (0.18365591397849462, 0.09182795698924731),\n",
       " (0.18345864661654138, 0.09172932330827069),\n",
       " (0.1832618025751073, 0.09163090128755365),\n",
       " (0.18306538049303325, 0.09153269024651663),\n",
       " (0.18286937901498931, 0.09143468950749466),\n",
       " (0.18267379679144385, 0.09133689839572193),\n",
       " (0.1824786324786325, 0.09123931623931625),\n",
       " (0.18271077908217714, 0.09135538954108857),\n",
       " (0.18251599147121533, 0.09125799573560767),\n",
       " (0.18274760383386585, 0.09137380191693292),\n",
       " (0.18255319148936172, 0.09127659574468086),\n",
       " (0.18235919234856537, 0.09117959617428269),\n",
       " (0.18216560509554142, 0.09108280254777071),\n",
       " (0.1819724284199364, 0.0909862142099682),\n",
       " (0.18177966101694915, 0.09088983050847457),\n",
       " (0.182010582010582, 0.091005291005291),\n",
       " (0.18181818181818185, 0.09090909090909093),\n",
       " (0.1816261879619852, 0.0908130939809926),\n",
       " (0.18185654008438823, 0.09092827004219411),\n",
       " (0.18166491043203373, 0.09083245521601686),\n",
       " (0.18147368421052634, 0.09073684210526317),\n",
       " (0.18170347003154574, 0.09085173501577287),\n",
       " (0.18193277310924372, 0.09096638655462186),\n",
       " (0.1821615949632739, 0.09108079748163694),\n",
       " (0.18238993710691825, 0.09119496855345913),\n",
       " (0.18219895287958116, 0.09109947643979058),\n",
       " (0.18200836820083685, 0.09100418410041843),\n",
       " (0.18223615464994777, 0.09111807732497389),\n",
       " (0.18204592901878916, 0.09102296450939458),\n",
       " (0.1818561001042753, 0.09092805005213765),\n",
       " (0.1816666666666667, 0.09083333333333335),\n",
       " (0.181477627471384, 0.090738813735692),\n",
       " (0.1812889812889813, 0.09064449064449065),\n",
       " (0.18110072689511944, 0.09055036344755972),\n",
       " (0.18091286307053941, 0.09045643153526971),\n",
       " (0.18113989637305702, 0.09056994818652851),\n",
       " (0.18095238095238095, 0.09047619047619047),\n",
       " (0.18076525336091007, 0.09038262668045503),\n",
       " (0.18057851239669423, 0.09028925619834711),\n",
       " (0.18080495356037152, 0.09040247678018576),\n",
       " (0.1806185567010309, 0.09030927835051546),\n",
       " (0.1808444902162719, 0.09042224510813596),\n",
       " (0.18065843621399177, 0.09032921810699589),\n",
       " (0.18088386433710177, 0.09044193216855088),\n",
       " (0.1806981519507187, 0.09034907597535935),\n",
       " (0.1805128205128205, 0.09025641025641025),\n",
       " (0.180327868852459, 0.0901639344262295),\n",
       " (0.18014329580348007, 0.09007164790174003),\n",
       " (0.1803680981595092, 0.0901840490797546),\n",
       " (0.1801838610827375, 0.09009193054136876),\n",
       " (0.18040816326530612, 0.09020408163265306),\n",
       " (0.18063200815494393, 0.09031600407747196),\n",
       " (0.1804480651731161, 0.09022403258655805),\n",
       " (0.18026449643947104, 0.09013224821973552),\n",
       " (0.18008130081300813, 0.09004065040650407),\n",
       " (0.1798984771573604, 0.0899492385786802),\n",
       " (0.17971602434077083, 0.08985801217038542),\n",
       " (0.17953394123606892, 0.08976697061803446),\n",
       " (0.17975708502024293, 0.08987854251012146),\n",
       " (0.1795753286147624, 0.0897876643073812),\n",
       " (0.17979797979797982, 0.08989898989898991),\n",
       " (0.1796165489404642, 0.0898082744702321),\n",
       " (0.17943548387096775, 0.08971774193548387),\n",
       " (0.17925478348439072, 0.08962739174219536),\n",
       " (0.1790744466800805, 0.08953722334004025),\n",
       " (0.17889447236180908, 0.08944723618090454),\n",
       " (0.178714859437751, 0.0893574297188755),\n",
       " (0.17853560682046138, 0.08926780341023069),\n",
       " (0.1783567134268537, 0.08917835671342685),\n",
       " (0.17817817817817816, 0.08908908908908908),\n",
       " (0.1784, 0.0892),\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng.dropouts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
